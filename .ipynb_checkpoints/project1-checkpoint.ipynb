{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from helpers.least_squares import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from helpers.proj1_helpers import *\n",
    "# Aya : '/Users/mac/Documents/GitHub/ml-project-1-aaa_project1/data/train.csv' \n",
    "DATA_TRAIN_PATH = '/home/adeye/Documents/EPFL/MA1/ML_course/projects/ml-project-1-aaa_project1/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scripts.helpers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_41168/1035456519.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_descent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleast_squares\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic_gradient_descent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mridge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scripts.helpers'"
     ]
    }
   ],
   "source": [
    "from helpers.gradient_descent import *\n",
    "from helpers.least_squares import *\n",
    "from helpers.stochastic_gradient_descent import *\n",
    "from helpers.ridge import *\n",
    "from helpers.processing import *\n",
    "from helpers.cross_validation import *\n",
    "from helpers.feature_transformation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing our DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jet_0,label_0,jet_1,label_1,jet_2_3, label_2_3= pre_process_data_pipeline(tX,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Algorithms After Cleaning Our DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Squares With Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_0,label_0,jet_1,label_1,jet_2_3, label_2_3= groupy_by_jet_num(tX,y)\n",
    "    \n",
    "remove_outliers(tX)\n",
    "init_weights = np.ones((30,))\n",
    "print(y.shape)\n",
    "print(tX.shape)\n",
    "\n",
    "weights,loss =  gradient_descent(y, tX,init_weights , 50000, .01)\n",
    "\n",
    "print(weights)\n",
    "print(\"{:e}\".format(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares with OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight,loss= least_squares(y,tX)\n",
    "print(compute_squared_loss(y,tX,weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares With Stochastic Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_outliers(tX)\n",
    "init_weights = np.ones((30,))\n",
    "print(y.shape)\n",
    "print(tX.shape)\n",
    "\n",
    "weights,loss =  stochastic_gradient_descent(y, tX,init_weights , 500, 0.01, batch_size=1)\n",
    "\n",
    "print(weights)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares With Ridge Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, loss = ridge(y, tX, 0.025)\n",
    "print(\"{:e}\".format(np.sqrt(2*loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the best hyperparameters for ridge regression (degree and lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each one of our subsets we find the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 0.0  Lambda: 1e-15  RMSE Training: 0.8716352293003101  RMSE Test: 0.8739571550961067\n",
      "Degree: 1.0  Lambda: 1e-15  RMSE Training: 0.7086855263328693  RMSE Test: 0.7107033856724818\n",
      "Degree: 2.0  Lambda: 1e-15  RMSE Training: 0.6919061284061623  RMSE Test: 0.6943507155440913\n",
      "Degree: 3.0  Lambda: 1e-15  RMSE Training: 0.6844634666613373  RMSE Test: 0.6877682696069484\n",
      "Degree: 4.0  Lambda: 1e-15  RMSE Training: 0.6803593304280569  RMSE Test: 0.6839350544842328\n",
      "Degree: 5.0  Lambda: 1e-15  RMSE Training: 0.679389251616092  RMSE Test: 0.685851532246559\n",
      "Degree: 6.0  Lambda: 1e-15  RMSE Training: 4.471430442672017  RMSE Test: 3.9340782231183207\n",
      "Degree: 7.0  Lambda: 1e-15  RMSE Training: 1.5242561924239442  RMSE Test: 1.9302103982949075\n",
      "Degree: 8.0  Lambda: 1e-15  RMSE Training: 0.9903984726008506  RMSE Test: 1.036472994850342\n",
      "Degree: 9.0  Lambda: 1e-15  RMSE Training: 275684322.9719708  RMSE Test: 275147571.9826255\n",
      "Degree: 0.0  Lambda: 1e-14  RMSE Training: 0.8716352293003101  RMSE Test: 0.8739571550961067\n",
      "Degree: 1.0  Lambda: 1e-14  RMSE Training: 0.7086857595693523  RMSE Test: 0.7107006430909202\n",
      "Degree: 2.0  Lambda: 1e-14  RMSE Training: 0.6919087495954186  RMSE Test: 0.6943477566974677\n",
      "Degree: 3.0  Lambda: 1e-14  RMSE Training: 0.6845838130536162  RMSE Test: 0.6878185064413879\n",
      "Degree: 4.0  Lambda: 1e-14  RMSE Training: 0.6803994352786547  RMSE Test: 0.683953221772922\n",
      "Degree: 5.0  Lambda: 1e-14  RMSE Training: 0.6794668447582364  RMSE Test: 0.6853204606773018\n",
      "Degree: 6.0  Lambda: 1e-14  RMSE Training: 0.7321682217659327  RMSE Test: 0.7219917196260447\n",
      "Degree: 7.0  Lambda: 1e-14  RMSE Training: 0.701848437736942  RMSE Test: 0.7659892563751354\n",
      "Degree: 8.0  Lambda: 1e-14  RMSE Training: 0.7374855383573407  RMSE Test: 0.9168611346436588\n",
      "Degree: 9.0  Lambda: 1e-14  RMSE Training: 5945634.3829141725  RMSE Test: 5944183.989779579\n",
      "Degree: 0.0  Lambda: 1e-13  RMSE Training: 0.8716352293003101  RMSE Test: 0.8739571550961063\n",
      "Degree: 1.0  Lambda: 1e-13  RMSE Training: 0.708686840918159  RMSE Test: 0.710694697720796\n",
      "Degree: 2.0  Lambda: 1e-13  RMSE Training: 0.6919347161055568  RMSE Test: 0.6943516064982458\n",
      "Degree: 3.0  Lambda: 1e-13  RMSE Training: 0.684727639008728  RMSE Test: 0.6878478646741456\n",
      "Degree: 4.0  Lambda: 1e-13  RMSE Training: 0.6805301802086199  RMSE Test: 0.6840623860677012\n",
      "Degree: 5.0  Lambda: 1e-13  RMSE Training: 0.6806068795890532  RMSE Test: 0.6862334838889779\n",
      "Degree: 6.0  Lambda: 1e-13  RMSE Training: 0.6825441156186519  RMSE Test: 0.6844686575867247\n",
      "Degree: 7.0  Lambda: 1e-13  RMSE Training: 0.7022110673575035  RMSE Test: 0.979169095610002\n",
      "Degree: 8.0  Lambda: 1e-13  RMSE Training: 0.7823910517960541  RMSE Test: 0.8607218712029251\n",
      "Degree: 9.0  Lambda: 1e-13  RMSE Training: 1400750.5515916795  RMSE Test: 1411003.6035039923\n",
      "Degree: 0.0  Lambda: 1e-12  RMSE Training: 0.8716352293003101  RMSE Test: 0.8739571550961035\n",
      "Degree: 1.0  Lambda: 1e-12  RMSE Training: 0.7086875267455587  RMSE Test: 0.7106916258002716\n",
      "Degree: 2.0  Lambda: 1e-12  RMSE Training: 0.6920921864134053  RMSE Test: 0.6944374689214845\n",
      "Degree: 3.0  Lambda: 1e-12  RMSE Training: 0.6848062582196826  RMSE Test: 0.6878584448450161\n",
      "Degree: 4.0  Lambda: 1e-12  RMSE Training: 0.6806355586225065  RMSE Test: 0.6841630684934419\n",
      "Degree: 5.0  Lambda: 1e-12  RMSE Training: 0.6796636647021105  RMSE Test: 0.6850748893852211\n",
      "Degree: 6.0  Lambda: 1e-12  RMSE Training: 0.6816805655964602  RMSE Test: 0.684168242333573\n",
      "Degree: 7.0  Lambda: 1e-12  RMSE Training: 0.6945380060829776  RMSE Test: 0.835174071548791\n",
      "Degree: 8.0  Lambda: 1e-12  RMSE Training: 0.6892630925121964  RMSE Test: 0.7740451463987091\n",
      "Degree: 9.0  Lambda: 1e-12  RMSE Training: 6713617.14934901  RMSE Test: 6728430.459766845\n",
      "Degree: 0.0  Lambda: 1e-11  RMSE Training: 0.8716352293003103  RMSE Test: 0.8739571550960754\n",
      "Degree: 1.0  Lambda: 1e-11  RMSE Training: 0.7086891396563442  RMSE Test: 0.7107056866626358\n",
      "Degree: 2.0  Lambda: 1e-11  RMSE Training: 0.6923159405976778  RMSE Test: 0.6945822123326814\n",
      "Degree: 3.0  Lambda: 1e-11  RMSE Training: 0.684968460605349  RMSE Test: 0.6879151110113177\n",
      "Degree: 4.0  Lambda: 1e-11  RMSE Training: 0.6807188524060986  RMSE Test: 0.6841486423640173\n",
      "Degree: 5.0  Lambda: 1e-11  RMSE Training: 0.6801568980574194  RMSE Test: 0.685298710106332\n",
      "Degree: 6.0  Lambda: 1e-11  RMSE Training: 0.6803316449623563  RMSE Test: 0.6917214075431811\n",
      "Degree: 7.0  Lambda: 1e-11  RMSE Training: 0.7164905912702737  RMSE Test: 0.8673685217676832\n",
      "Degree: 8.0  Lambda: 1e-11  RMSE Training: 12.683293044092053  RMSE Test: 12.767656916833989\n",
      "Degree: 9.0  Lambda: 1e-11  RMSE Training: 13919090.171466608  RMSE Test: 13910935.017095586\n",
      "Degree: 0.0  Lambda: 1e-10  RMSE Training: 0.8716352293003101  RMSE Test: 0.8739571550957945\n",
      "Degree: 1.0  Lambda: 1e-10  RMSE Training: 0.7087895197699976  RMSE Test: 0.7109558452872995\n",
      "Degree: 2.0  Lambda: 1e-10  RMSE Training: 0.6923995672008324  RMSE Test: 0.6945924569947138\n",
      "Degree: 3.0  Lambda: 1e-10  RMSE Training: 0.6850715424580628  RMSE Test: 0.687986279221413\n",
      "Degree: 4.0  Lambda: 1e-10  RMSE Training: 0.6808936504931722  RMSE Test: 0.6841767141274431\n",
      "Degree: 5.0  Lambda: 1e-10  RMSE Training: 0.6798622682865311  RMSE Test: 0.6852817917623361\n",
      "Degree: 6.0  Lambda: 1e-10  RMSE Training: 0.6816041830409202  RMSE Test: 0.6861273490314865\n",
      "Degree: 7.0  Lambda: 1e-10  RMSE Training: 0.7156175340285162  RMSE Test: 1.2553421881473699\n",
      "Degree: 8.0  Lambda: 1e-10  RMSE Training: 1.8716655101869353  RMSE Test: 2.0582387708009753\n",
      "Degree: 9.0  Lambda: 1e-10  RMSE Training: 1077420.9014859074  RMSE Test: 1078146.5981584685\n",
      "Degree: 0.0  Lambda: 1e-09  RMSE Training: 0.8716352293003103  RMSE Test: 0.8739571550929854\n",
      "Degree: 1.0  Lambda: 1e-09  RMSE Training: 0.7111394676422661  RMSE Test: 0.7139585073968795\n",
      "Degree: 2.0  Lambda: 1e-09  RMSE Training: 0.6924437009182073  RMSE Test: 0.6945790022304195\n",
      "Degree: 3.0  Lambda: 1e-09  RMSE Training: 0.6851157112007209  RMSE Test: 0.6879769682941546\n",
      "Degree: 4.0  Lambda: 1e-09  RMSE Training: 0.6809643715732374  RMSE Test: 0.6841613623737282\n",
      "Degree: 5.0  Lambda: 1e-09  RMSE Training: 0.6813947596092009  RMSE Test: 0.686322549183179\n",
      "Degree: 6.0  Lambda: 1e-09  RMSE Training: 0.6919645422507967  RMSE Test: 0.71402038433872\n",
      "Degree: 7.0  Lambda: 1e-09  RMSE Training: 1.775857913611313  RMSE Test: 2.2189633470221266\n",
      "Degree: 8.0  Lambda: 1e-09  RMSE Training: 1.2458137814637624  RMSE Test: 1.9822440625246571\n",
      "Degree: 9.0  Lambda: 1e-09  RMSE Training: 394090.31430610316  RMSE Test: 394072.47894737043\n",
      "Degree: 0.0  Lambda: 1e-08  RMSE Training: 0.8716352293003103  RMSE Test: 0.873957155064895\n",
      "Degree: 1.0  Lambda: 1e-08  RMSE Training: 0.7163220836726449  RMSE Test: 0.7196342509910061\n",
      "Degree: 2.0  Lambda: 1e-08  RMSE Training: 0.6929060806441814  RMSE Test: 0.694960782350923\n",
      "Degree: 3.0  Lambda: 1e-08  RMSE Training: 0.6851833439871109  RMSE Test: 0.6879835099118917\n",
      "Degree: 4.0  Lambda: 1e-08  RMSE Training: 0.6810684538163048  RMSE Test: 0.6840257432354263\n",
      "Degree: 5.0  Lambda: 1e-08  RMSE Training: 0.6914287908093735  RMSE Test: 0.6976673105359886\n",
      "Degree: 6.0  Lambda: 1e-08  RMSE Training: 0.7802851327348949  RMSE Test: 0.7831633193516706\n",
      "Degree: 7.0  Lambda: 1e-08  RMSE Training: 1.1577547069612915  RMSE Test: 1.402448433976183\n",
      "Degree: 8.0  Lambda: 1e-08  RMSE Training: 1.7262044980879743  RMSE Test: 4.6289065043422095\n",
      "Degree: 9.0  Lambda: 1e-08  RMSE Training: 870190.7138354384  RMSE Test: 873094.4929415209\n",
      "Degree: 0.0  Lambda: 1e-07  RMSE Training: 0.8716352293003128  RMSE Test: 0.8739571547839919\n",
      "Degree: 1.0  Lambda: 1e-07  RMSE Training: 0.7185620365033232  RMSE Test: 0.7220424704063181\n",
      "Degree: 2.0  Lambda: 1e-07  RMSE Training: 0.6938768264988083  RMSE Test: 0.6960028366677288\n",
      "Degree: 3.0  Lambda: 1e-07  RMSE Training: 0.6855012711913998  RMSE Test: 0.6883171851030504\n",
      "Degree: 4.0  Lambda: 1e-07  RMSE Training: 0.6812532928562742  RMSE Test: 0.6835793750228334\n",
      "Degree: 5.0  Lambda: 1e-07  RMSE Training: 0.6805070928113405  RMSE Test: 0.6896980842108827\n",
      "Degree: 6.0  Lambda: 1e-07  RMSE Training: 0.6796963748425304  RMSE Test: 0.6875209854835567\n",
      "Degree: 7.0  Lambda: 1e-07  RMSE Training: 2.268436686859812  RMSE Test: 3.514481959574487\n",
      "Degree: 8.0  Lambda: 1e-07  RMSE Training: 4179.395111037979  RMSE Test: 3967.688670067164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 9.0  Lambda: 1e-07  RMSE Training: 3115558.2641369733  RMSE Test: 3097132.616726127\n",
      "Degree: 0.0  Lambda: 1e-06  RMSE Training: 0.8716352293005618  RMSE Test: 0.8739571519751894\n",
      "Degree: 1.0  Lambda: 1e-06  RMSE Training: 0.7189628992582472  RMSE Test: 0.7224887981787478\n",
      "Degree: 2.0  Lambda: 1e-06  RMSE Training: 0.695238276504683  RMSE Test: 0.6975853636288122\n",
      "Degree: 3.0  Lambda: 1e-06  RMSE Training: 0.6863034652271736  RMSE Test: 0.6892544599239342\n",
      "Degree: 4.0  Lambda: 1e-06  RMSE Training: 0.6824293200935875  RMSE Test: 0.6849783514984122\n",
      "Degree: 5.0  Lambda: 1e-06  RMSE Training: 0.6817114439318812  RMSE Test: 0.6893059159237941\n",
      "Degree: 6.0  Lambda: 1e-06  RMSE Training: 0.6815308777327813  RMSE Test: 0.6890642199638392\n",
      "Degree: 7.0  Lambda: 1e-06  RMSE Training: 3.4435922664728067  RMSE Test: 3.7412322581121047\n",
      "Degree: 8.0  Lambda: 1e-06  RMSE Training: 78.80885494019502  RMSE Test: 79.17844592184618\n",
      "Degree: 9.0  Lambda: 1e-06  RMSE Training: 3065101.4425722267  RMSE Test: 3097091.1979589937\n",
      "Degree: 0.0  Lambda: 1e-05  RMSE Training: 0.8716352293254616  RMSE Test: 0.8739571239098879\n",
      "Degree: 1.0  Lambda: 1e-05  RMSE Training: 0.7203547525197035  RMSE Test: 0.7239029736134098\n",
      "Degree: 2.0  Lambda: 1e-05  RMSE Training: 0.6964731635199692  RMSE Test: 0.698875068961465\n",
      "Degree: 3.0  Lambda: 1e-05  RMSE Training: 0.6881608889699039  RMSE Test: 0.6910483798928276\n",
      "Degree: 4.0  Lambda: 1e-05  RMSE Training: 0.6846930136414392  RMSE Test: 0.6877316512917462\n",
      "Degree: 5.0  Lambda: 1e-05  RMSE Training: 0.6827535477598003  RMSE Test: 0.6873033106607849\n",
      "Degree: 6.0  Lambda: 1e-05  RMSE Training: 0.683342254004323  RMSE Test: 0.7487085490274822\n",
      "Degree: 7.0  Lambda: 1e-05  RMSE Training: 1.7860579778580945  RMSE Test: 1.781015930083044\n",
      "Degree: 8.0  Lambda: 1e-05  RMSE Training: 426.9972461361419  RMSE Test: 427.97053208107366\n",
      "Degree: 9.0  Lambda: 1e-05  RMSE Training: 620865.1498002459  RMSE Test: 622351.3407784335\n",
      "Degree: 0.0  Lambda: 0.0001  RMSE Training: 0.8716352318148358  RMSE Test: 0.8739568455286811\n",
      "Degree: 1.0  Lambda: 0.0001  RMSE Training: 0.7290104088344547  RMSE Test: 0.7323546198224788\n",
      "Degree: 2.0  Lambda: 0.0001  RMSE Training: 0.7007673361066492  RMSE Test: 0.703070161023683\n",
      "Degree: 3.0  Lambda: 0.0001  RMSE Training: 0.6936890528803723  RMSE Test: 0.6963556703095033\n",
      "Degree: 4.0  Lambda: 0.0001  RMSE Training: 0.6889944719298469  RMSE Test: 0.691568369579984\n",
      "Degree: 5.0  Lambda: 0.0001  RMSE Training: 0.6887501649098169  RMSE Test: 0.6899426452313061\n",
      "Degree: 6.0  Lambda: 0.0001  RMSE Training: 0.7930696961890652  RMSE Test: 0.8177072220442921\n",
      "Degree: 7.0  Lambda: 0.0001  RMSE Training: 3.485210937842696  RMSE Test: 3.543187202999865\n",
      "Degree: 8.0  Lambda: 0.0001  RMSE Training: 134.72866718943345  RMSE Test: 135.15759749180017\n",
      "Degree: 9.0  Lambda: 0.0001  RMSE Training: 2479969.419942419  RMSE Test: 2472743.3288711184\n",
      "Degree: 0.0  Lambda: 0.001  RMSE Training: 0.8716354801425664  RMSE Test: 0.8739542882912394\n",
      "Degree: 1.0  Lambda: 0.001  RMSE Training: 0.7350526576876995  RMSE Test: 0.7384560782941918\n",
      "Degree: 2.0  Lambda: 0.001  RMSE Training: 0.7080689407871652  RMSE Test: 0.7105474355810075\n",
      "Degree: 3.0  Lambda: 0.001  RMSE Training: 0.7011501451948755  RMSE Test: 0.7036558905725705\n",
      "Degree: 4.0  Lambda: 0.001  RMSE Training: 0.696094337017671  RMSE Test: 0.6985648259548611\n",
      "Degree: 5.0  Lambda: 0.001  RMSE Training: 0.6931201122532971  RMSE Test: 0.695476258060871\n",
      "Degree: 6.0  Lambda: 0.001  RMSE Training: 21.611862687315927  RMSE Test: 21.676169153764125\n",
      "Degree: 7.0  Lambda: 0.001  RMSE Training: 19.6083948411026  RMSE Test: 19.65082100870067\n",
      "Degree: 8.0  Lambda: 0.001  RMSE Training: 47.86145765270827  RMSE Test: 47.979027918554095\n",
      "Degree: 9.0  Lambda: 0.001  RMSE Training: 4917617.520692861  RMSE Test: 4921289.609055726\n",
      "Degree: 0.0  Lambda: 0.01  RMSE Training: 0.8716597149558242  RMSE Test: 0.8739507788989643\n",
      "Degree: 1.0  Lambda: 0.01  RMSE Training: 0.7453706512193431  RMSE Test: 0.7483534518322749\n",
      "Degree: 2.0  Lambda: 0.01  RMSE Training: 0.7236014812600324  RMSE Test: 0.7261248107318051\n",
      "Degree: 3.0  Lambda: 0.01  RMSE Training: 0.7112239983328534  RMSE Test: 0.7133888387728444\n",
      "Degree: 4.0  Lambda: 0.01  RMSE Training: 0.7046524125072339  RMSE Test: 0.7074747035781019\n",
      "Degree: 5.0  Lambda: 0.01  RMSE Training: 0.7001515078470718  RMSE Test: 0.7029746062983486\n",
      "Degree: 6.0  Lambda: 0.01  RMSE Training: 3.0659524435359553  RMSE Test: 3.0626114029607443\n",
      "Degree: 7.0  Lambda: 0.01  RMSE Training: 132.32777626244584  RMSE Test: 132.80825758107642\n",
      "Degree: 8.0  Lambda: 0.01  RMSE Training: 616.8373416319885  RMSE Test: 617.5695292350797\n",
      "Degree: 9.0  Lambda: 0.01  RMSE Training: 16310753.462492157  RMSE Test: 16313761.205744023\n",
      "Degree: 0.0  Lambda: 0.1  RMSE Training: 0.8735851833072512  RMSE Test: 0.8756274193934311\n",
      "Degree: 1.0  Lambda: 0.1  RMSE Training: 0.7748816034127202  RMSE Test: 0.7774053972525445\n",
      "Degree: 2.0  Lambda: 0.1  RMSE Training: 0.7549857203510286  RMSE Test: 0.7575684523097234\n",
      "Degree: 3.0  Lambda: 0.1  RMSE Training: 0.7458877557445736  RMSE Test: 0.748481393103287\n",
      "Degree: 4.0  Lambda: 0.1  RMSE Training: 0.7399679957235301  RMSE Test: 0.7428744058204739\n",
      "Degree: 5.0  Lambda: 0.1  RMSE Training: 0.7353147974306051  RMSE Test: 0.7385590776334585\n",
      "Degree: 6.0  Lambda: 0.1  RMSE Training: 47.95947895168043  RMSE Test: 46.721709491494074\n",
      "Degree: 7.0  Lambda: 0.1  RMSE Training: 377.42024701918547  RMSE Test: 377.4359711220688\n",
      "Degree: 8.0  Lambda: 0.1  RMSE Training: 17660.091885197948  RMSE Test: 17666.556969727222\n",
      "Degree: 9.0  Lambda: 0.1  RMSE Training: 41599609.95407201  RMSE Test: 41619229.17910023\n",
      "Degree: 0.0  Lambda: 1.0  RMSE Training: 0.9160138147880945  RMSE Test: 0.9169562379337407\n",
      "Degree: 1.0  Lambda: 1.0  RMSE Training: 0.8400093568378827  RMSE Test: 0.8421091218086663\n",
      "Degree: 2.0  Lambda: 1.0  RMSE Training: 0.8308334504148736  RMSE Test: 0.8330365146573676\n",
      "Degree: 3.0  Lambda: 1.0  RMSE Training: 0.823669105524522  RMSE Test: 0.8261294599505332\n",
      "Degree: 4.0  Lambda: 1.0  RMSE Training: 0.8195785906034867  RMSE Test: 0.822066684888379\n",
      "Degree: 5.0  Lambda: 1.0  RMSE Training: 0.8127428177917624  RMSE Test: 0.8152555935020057\n",
      "Degree: 6.0  Lambda: 1.0  RMSE Training: 0.8056890480312079  RMSE Test: 0.8086253886120023\n",
      "Degree: 7.0  Lambda: 1.0  RMSE Training: 152.73277108104847  RMSE Test: 152.6703320569332\n",
      "Degree: 8.0  Lambda: 1.0  RMSE Training: 15021009.031602552  RMSE Test: 15000661.8938128\n",
      "Degree: 9.0  Lambda: 1.0  RMSE Training: 102343213.08827725  RMSE Test: 102184001.20283966\n",
      "\n",
      "\n",
      "\n",
      "*******JET 0 *************\n",
      "Lowest_error: 0.6835793750228334  Best degree: 4.0  Best lambda: 1e-07\n"
     ]
    }
   ],
   "source": [
    "#For jet_0 => find the best hyperparameters and find the weight that corresponds to those hyperparameters\n",
    "\n",
    "[lowest_error_0,best_degree_0,best_lambda_0,rmse_tr,rmse_te] = cross_validation_ridge(5,jet_0,label_0)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"*******JET 0 *************\")\n",
    "print(\"Lowest_error:\",lowest_error_0,\" Best degree:\",best_degree_0,\" Best lambda:\",best_lambda_0)\n",
    "    \n",
    "jet_0_extended = poly_expansion(jet_0,best_degree_0)\n",
    "w_jet_0,_ = ridge(label_0,jet_0_extended,best_lambda_0)\n",
    "\n",
    "#Lowest_error: 0.6892967230876204  Best degree: 4.0  Best lambda: 1e-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 0.0  Lambda: 1e-15  RMSE Training: 0.9584458028324001  RMSE Test: 0.9584548549842007\n",
      "Degree: 1.0  Lambda: 1e-15  RMSE Training: 0.8150372318209659  RMSE Test: 0.8155903871891537\n",
      "Degree: 2.0  Lambda: 1e-15  RMSE Training: 0.7879790503040164  RMSE Test: 0.7891919559477121\n",
      "Degree: 3.0  Lambda: 1e-15  RMSE Training: 0.7727684470737375  RMSE Test: 0.775523740267185\n",
      "Degree: 4.0  Lambda: 1e-15  RMSE Training: 0.7675655353145182  RMSE Test: 0.7737858215663196\n",
      "Degree: 5.0  Lambda: 1e-15  RMSE Training: 0.7592150516801699  RMSE Test: 0.774672845659431\n",
      "Degree: 6.0  Lambda: 1e-15  RMSE Training: 0.7609172619729823  RMSE Test: 0.7965901907775521\n",
      "Degree: 7.0  Lambda: 1e-15  RMSE Training: 0.751263150715015  RMSE Test: 0.9193844436726988\n",
      "Degree: 8.0  Lambda: 1e-15  RMSE Training: 0.7519527243432511  RMSE Test: 2.644639292327197\n",
      "Degree: 9.0  Lambda: 1e-15  RMSE Training: 0.7560253217989514  RMSE Test: 6.15635403123251\n",
      "Degree: 0.0  Lambda: 1e-14  RMSE Training: 0.9584458028324002  RMSE Test: 0.9584548549842007\n",
      "Degree: 1.0  Lambda: 1e-14  RMSE Training: 0.8150372947227215  RMSE Test: 0.8155896028233192\n",
      "Degree: 2.0  Lambda: 1e-14  RMSE Training: 0.7879823022636464  RMSE Test: 0.7891868557587424\n",
      "Degree: 3.0  Lambda: 1e-14  RMSE Training: 0.7728183439390814  RMSE Test: 0.7755245006104612\n",
      "Degree: 4.0  Lambda: 1e-14  RMSE Training: 0.7673049952262073  RMSE Test: 0.7737318382183234\n",
      "Degree: 5.0  Lambda: 1e-14  RMSE Training: 0.759329518438568  RMSE Test: 0.774505013405482\n",
      "Degree: 6.0  Lambda: 1e-14  RMSE Training: 0.7541907337066729  RMSE Test: 0.7892123352724056\n",
      "Degree: 7.0  Lambda: 1e-14  RMSE Training: 0.7541598840733781  RMSE Test: 2.628502526375578\n",
      "Degree: 8.0  Lambda: 1e-14  RMSE Training: 0.7504514883567361  RMSE Test: 2.687966545889915\n",
      "Degree: 9.0  Lambda: 1e-14  RMSE Training: 0.7536220337586825  RMSE Test: 6.219514384368789\n",
      "Degree: 0.0  Lambda: 1e-13  RMSE Training: 0.9584458028324001  RMSE Test: 0.9584548549842007\n",
      "Degree: 1.0  Lambda: 1e-13  RMSE Training: 0.8150399835727384  RMSE Test: 0.8155873816643068\n",
      "Degree: 2.0  Lambda: 1e-13  RMSE Training: 0.78808680900763  RMSE Test: 0.789256706618733\n",
      "Degree: 3.0  Lambda: 1e-13  RMSE Training: 0.7729015974187015  RMSE Test: 0.7755615378305363\n",
      "Degree: 4.0  Lambda: 1e-13  RMSE Training: 0.7673671248751561  RMSE Test: 0.7737860997004233\n",
      "Degree: 5.0  Lambda: 1e-13  RMSE Training: 0.759368464016583  RMSE Test: 0.7744669688734145\n",
      "Degree: 6.0  Lambda: 1e-13  RMSE Training: 0.7542838688016682  RMSE Test: 0.7883124083803817\n",
      "Degree: 7.0  Lambda: 1e-13  RMSE Training: 0.7517131726212732  RMSE Test: 1.0357596754630016\n",
      "Degree: 8.0  Lambda: 1e-13  RMSE Training: 0.7506613193778443  RMSE Test: 2.7183055450005082\n",
      "Degree: 9.0  Lambda: 1e-13  RMSE Training: 0.7990800860655457  RMSE Test: 9.555642310712479\n",
      "Degree: 0.0  Lambda: 1e-12  RMSE Training: 0.9584458028324001  RMSE Test: 0.9584548549842007\n",
      "Degree: 1.0  Lambda: 1e-12  RMSE Training: 0.8150534259574244  RMSE Test: 0.8155936548129146\n",
      "Degree: 2.0  Lambda: 1e-12  RMSE Training: 0.7892216655079273  RMSE Test: 0.7903151431031551\n",
      "Degree: 3.0  Lambda: 1e-12  RMSE Training: 0.7733156650284838  RMSE Test: 0.7759252115141203\n",
      "Degree: 4.0  Lambda: 1e-12  RMSE Training: 0.7674969469506477  RMSE Test: 0.7738703553489004\n",
      "Degree: 5.0  Lambda: 1e-12  RMSE Training: 0.7594276151749698  RMSE Test: 0.7743834026250374\n",
      "Degree: 6.0  Lambda: 1e-12  RMSE Training: 0.754349050421368  RMSE Test: 0.7877246498170642\n",
      "Degree: 7.0  Lambda: 1e-12  RMSE Training: 0.7514737711384345  RMSE Test: 0.9529807933039075\n",
      "Degree: 8.0  Lambda: 1e-12  RMSE Training: 0.7505509752891182  RMSE Test: 2.6575932241164786\n",
      "Degree: 9.0  Lambda: 1e-12  RMSE Training: 0.7527316466551418  RMSE Test: 5.326428360324985\n",
      "Degree: 0.0  Lambda: 1e-11  RMSE Training: 0.9584458028324004  RMSE Test: 0.9584548549842005\n",
      "Degree: 1.0  Lambda: 1e-11  RMSE Training: 0.8150625006333996  RMSE Test: 0.815596865371299\n",
      "Degree: 2.0  Lambda: 1e-11  RMSE Training: 0.7903268530407412  RMSE Test: 0.7913556465133567\n",
      "Degree: 3.0  Lambda: 1e-11  RMSE Training: 0.7750081094222995  RMSE Test: 0.7775755623812693\n",
      "Degree: 4.0  Lambda: 1e-11  RMSE Training: 0.7685928971091344  RMSE Test: 0.7748634547862979\n",
      "Degree: 5.0  Lambda: 1e-11  RMSE Training: 0.7599408696908603  RMSE Test: 0.7749019810547277\n",
      "Degree: 6.0  Lambda: 1e-11  RMSE Training: 0.7545834148197115  RMSE Test: 0.7838034160859413\n",
      "Degree: 7.0  Lambda: 1e-11  RMSE Training: 0.7515724412919215  RMSE Test: 0.9245902039661857\n",
      "Degree: 8.0  Lambda: 1e-11  RMSE Training: 0.7507271935156037  RMSE Test: 2.4999057252389165\n",
      "Degree: 9.0  Lambda: 1e-11  RMSE Training: 0.7501673181879643  RMSE Test: 5.595093868055472\n",
      "Degree: 0.0  Lambda: 1e-10  RMSE Training: 0.9584458028324002  RMSE Test: 0.9584548549842001\n",
      "Degree: 1.0  Lambda: 1e-10  RMSE Training: 0.8151865366856292  RMSE Test: 0.8157129802786331\n",
      "Degree: 2.0  Lambda: 1e-10  RMSE Training: 0.7905310055566301  RMSE Test: 0.7915119917085102\n",
      "Degree: 3.0  Lambda: 1e-10  RMSE Training: 0.7759726008275474  RMSE Test: 0.7784883715898538\n",
      "Degree: 4.0  Lambda: 1e-10  RMSE Training: 0.7701638051951707  RMSE Test: 0.7765542097916331\n",
      "Degree: 5.0  Lambda: 1e-10  RMSE Training: 0.7615756400977184  RMSE Test: 0.7767992185364699\n",
      "Degree: 6.0  Lambda: 1e-10  RMSE Training: 0.7560503421925439  RMSE Test: 0.7785865009146283\n",
      "Degree: 7.0  Lambda: 1e-10  RMSE Training: 0.7529222060617948  RMSE Test: 0.8793163211671009\n",
      "Degree: 8.0  Lambda: 1e-10  RMSE Training: 0.7518059655327347  RMSE Test: 2.273962949703145\n",
      "Degree: 9.0  Lambda: 1e-10  RMSE Training: 0.750985461475782  RMSE Test: 5.071930369674885\n",
      "Degree: 0.0  Lambda: 1e-09  RMSE Training: 0.9584458028324002  RMSE Test: 0.9584548549841967\n",
      "Degree: 1.0  Lambda: 1e-09  RMSE Training: 0.8166413910227133  RMSE Test: 0.8171496158469364\n",
      "Degree: 2.0  Lambda: 1e-09  RMSE Training: 0.790571992982535  RMSE Test: 0.7915340727353546\n",
      "Degree: 3.0  Lambda: 1e-09  RMSE Training: 0.7761484313797313  RMSE Test: 0.7786226388112621\n",
      "Degree: 4.0  Lambda: 1e-09  RMSE Training: 0.7705685535126727  RMSE Test: 0.7774558585660587\n",
      "Degree: 5.0  Lambda: 1e-09  RMSE Training: 0.7621909503107316  RMSE Test: 0.7776918986868382\n",
      "Degree: 6.0  Lambda: 1e-09  RMSE Training: 0.7570516346625251  RMSE Test: 0.7804631665429108\n",
      "Degree: 7.0  Lambda: 1e-09  RMSE Training: 0.7543888535420236  RMSE Test: 0.8534399820011762\n",
      "Degree: 8.0  Lambda: 1e-09  RMSE Training: 0.753461564315724  RMSE Test: 2.0902465200499942\n",
      "Degree: 9.0  Lambda: 1e-09  RMSE Training: 0.7526650959533423  RMSE Test: 4.705625040756876\n",
      "Degree: 0.0  Lambda: 1e-08  RMSE Training: 0.9584458028324002  RMSE Test: 0.958454854984162\n",
      "Degree: 1.0  Lambda: 1e-08  RMSE Training: 0.8233725788714594  RMSE Test: 0.8238539200203405\n",
      "Degree: 2.0  Lambda: 1e-08  RMSE Training: 0.7909261879281335  RMSE Test: 0.7918688504555406\n",
      "Degree: 3.0  Lambda: 1e-08  RMSE Training: 0.7762650078117859  RMSE Test: 0.7786502441027984\n",
      "Degree: 4.0  Lambda: 1e-08  RMSE Training: 0.7707130642274208  RMSE Test: 0.7777749187252224\n",
      "Degree: 5.0  Lambda: 1e-08  RMSE Training: 0.7623960296218073  RMSE Test: 0.7782003678097508\n",
      "Degree: 6.0  Lambda: 1e-08  RMSE Training: 0.7576956757592048  RMSE Test: 0.7850094842429487\n",
      "Degree: 7.0  Lambda: 1e-08  RMSE Training: 0.7548012482347861  RMSE Test: 0.838694848921679\n",
      "Degree: 8.0  Lambda: 1e-08  RMSE Training: 0.7539669611844922  RMSE Test: 1.827036059035191\n",
      "Degree: 9.0  Lambda: 1e-08  RMSE Training: 0.753320361688186  RMSE Test: 4.333214224561599\n",
      "Degree: 0.0  Lambda: 1e-07  RMSE Training: 0.958445802832401  RMSE Test: 0.9584548549838166\n",
      "Degree: 1.0  Lambda: 1e-07  RMSE Training: 0.8325716535618939  RMSE Test: 0.8330385856662211\n",
      "Degree: 2.0  Lambda: 1e-07  RMSE Training: 0.7940177182874931  RMSE Test: 0.7949371521602829\n",
      "Degree: 3.0  Lambda: 1e-07  RMSE Training: 0.7771645555832787  RMSE Test: 0.7794228606168825\n",
      "Degree: 4.0  Lambda: 1e-07  RMSE Training: 0.771294176003011  RMSE Test: 0.7781545869184335\n",
      "Degree: 5.0  Lambda: 1e-07  RMSE Training: 0.7638211000671168  RMSE Test: 0.78049704210157\n",
      "Degree: 6.0  Lambda: 1e-07  RMSE Training: 0.758451348396576  RMSE Test: 0.7804253627465587\n",
      "Degree: 7.0  Lambda: 1e-07  RMSE Training: 0.7554419676577715  RMSE Test: 0.8477069471415668\n",
      "Degree: 8.0  Lambda: 1e-07  RMSE Training: 0.7545097493088083  RMSE Test: 1.6006711561831117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 9.0  Lambda: 1e-07  RMSE Training: 0.7538252189072934  RMSE Test: 3.5199686499058105\n",
      "Degree: 0.0  Lambda: 1e-06  RMSE Training: 0.9584458028324777  RMSE Test: 0.9584548549804308\n",
      "Degree: 1.0  Lambda: 1e-06  RMSE Training: 0.8347999582466455  RMSE Test: 0.8352621325506121\n",
      "Degree: 2.0  Lambda: 1e-06  RMSE Training: 0.803086272565302  RMSE Test: 0.8039953015202626\n",
      "Degree: 3.0  Lambda: 1e-06  RMSE Training: 0.7826750889673868  RMSE Test: 0.7848680885085401\n",
      "Degree: 4.0  Lambda: 1e-06  RMSE Training: 0.7744096297509017  RMSE Test: 0.7807435560589588\n",
      "Degree: 5.0  Lambda: 1e-06  RMSE Training: 0.7669923206428291  RMSE Test: 0.7837591070295807\n",
      "Degree: 6.0  Lambda: 1e-06  RMSE Training: 0.7609305353855893  RMSE Test: 0.770414083947405\n",
      "Degree: 7.0  Lambda: 1e-06  RMSE Training: 0.7572435153244736  RMSE Test: 0.9335335220253889\n",
      "Degree: 8.0  Lambda: 1e-06  RMSE Training: 0.7560537492341214  RMSE Test: 1.467621334979674\n",
      "Degree: 9.0  Lambda: 1e-06  RMSE Training: 0.755366673704639  RMSE Test: 2.0225763453039374\n",
      "Degree: 0.0  Lambda: 1e-05  RMSE Training: 0.9584458028401481  RMSE Test: 0.9584548549534769\n",
      "Degree: 1.0  Lambda: 1e-05  RMSE Training: 0.8356643956721062  RMSE Test: 0.8361129644861712\n",
      "Degree: 2.0  Lambda: 1e-05  RMSE Training: 0.8070679666030607  RMSE Test: 0.8079549766964689\n",
      "Degree: 3.0  Lambda: 1e-05  RMSE Training: 0.7907774900647202  RMSE Test: 0.7929509921212125\n",
      "Degree: 4.0  Lambda: 1e-05  RMSE Training: 0.7829867453868238  RMSE Test: 0.7889248232411252\n",
      "Degree: 5.0  Lambda: 1e-05  RMSE Training: 0.7747197300735573  RMSE Test: 0.7881755104118857\n",
      "Degree: 6.0  Lambda: 1e-05  RMSE Training: 0.7680816945379041  RMSE Test: 0.7906606823550171\n",
      "Degree: 7.0  Lambda: 1e-05  RMSE Training: 0.7650142260342881  RMSE Test: 1.0680799201976652\n",
      "Degree: 8.0  Lambda: 1e-05  RMSE Training: 0.7632995569927137  RMSE Test: 1.0972438023257045\n",
      "Degree: 9.0  Lambda: 1e-05  RMSE Training: 0.761493452754065  RMSE Test: 1.7433724255151675\n",
      "Degree: 0.0  Lambda: 0.0001  RMSE Training: 0.9584458036070099  RMSE Test: 0.9584548553740199\n",
      "Degree: 1.0  Lambda: 0.0001  RMSE Training: 0.8388411342226378  RMSE Test: 0.8392549703243875\n",
      "Degree: 2.0  Lambda: 0.0001  RMSE Training: 0.8079465151738627  RMSE Test: 0.8087366211217777\n",
      "Degree: 3.0  Lambda: 0.0001  RMSE Training: 0.7969971217750363  RMSE Test: 0.7989710305126303\n",
      "Degree: 4.0  Lambda: 0.0001  RMSE Training: 0.7881752879289763  RMSE Test: 0.7935875017623075\n",
      "Degree: 5.0  Lambda: 0.0001  RMSE Training: 0.7808963063925385  RMSE Test: 0.7836288704434531\n",
      "Degree: 6.0  Lambda: 0.0001  RMSE Training: 0.7783754532658818  RMSE Test: 0.8783851118989545\n",
      "Degree: 7.0  Lambda: 0.0001  RMSE Training: 0.7768848567941701  RMSE Test: 0.9170358574052795\n",
      "Degree: 8.0  Lambda: 0.0001  RMSE Training: 0.773813904413542  RMSE Test: 1.048284801506182\n",
      "Degree: 9.0  Lambda: 0.0001  RMSE Training: 0.7715682341157833  RMSE Test: 2.7591968695981635\n",
      "Degree: 0.0  Lambda: 0.001  RMSE Training: 0.9584458801053849  RMSE Test: 0.9584549284018159\n",
      "Degree: 1.0  Lambda: 0.001  RMSE Training: 0.8445716926864423  RMSE Test: 0.844898110123508\n",
      "Degree: 2.0  Lambda: 0.001  RMSE Training: 0.8141917812041125  RMSE Test: 0.8147510109699025\n",
      "Degree: 3.0  Lambda: 0.001  RMSE Training: 0.8033620928628178  RMSE Test: 0.80455417330587\n",
      "Degree: 4.0  Lambda: 0.001  RMSE Training: 0.7942979009954648  RMSE Test: 0.7959340508284587\n",
      "Degree: 5.0  Lambda: 0.001  RMSE Training: 0.7906683605268597  RMSE Test: 0.8092523677035125\n",
      "Degree: 6.0  Lambda: 0.001  RMSE Training: 0.7890065267096151  RMSE Test: 0.8454751910838023\n",
      "Degree: 7.0  Lambda: 0.001  RMSE Training: 0.7841583672097314  RMSE Test: 0.7981607426484896\n",
      "Degree: 8.0  Lambda: 0.001  RMSE Training: 0.781682895570338  RMSE Test: 1.6257482143147375\n",
      "Degree: 9.0  Lambda: 0.001  RMSE Training: 0.7803485362313688  RMSE Test: 2.0718208859150002\n",
      "Degree: 0.0  Lambda: 0.01  RMSE Training: 0.9584533458143862  RMSE Test: 0.9584623586925332\n",
      "Degree: 1.0  Lambda: 0.01  RMSE Training: 0.8615975500202916  RMSE Test: 0.8617892406080812\n",
      "Degree: 2.0  Lambda: 0.01  RMSE Training: 0.8386591203858245  RMSE Test: 0.8391002327200097\n",
      "Degree: 3.0  Lambda: 0.01  RMSE Training: 0.818121066577641  RMSE Test: 0.8191766201354411\n",
      "Degree: 4.0  Lambda: 0.01  RMSE Training: 0.8085281289472313  RMSE Test: 0.8124124213576387\n",
      "Degree: 5.0  Lambda: 0.01  RMSE Training: 0.8048765286272085  RMSE Test: 0.8156398632304341\n",
      "Degree: 6.0  Lambda: 0.01  RMSE Training: 0.7986718823959992  RMSE Test: 0.8029682678726797\n",
      "Degree: 7.0  Lambda: 0.01  RMSE Training: 0.7959814041757338  RMSE Test: 1.008646250609833\n",
      "Degree: 8.0  Lambda: 0.01  RMSE Training: 0.7946316102358654  RMSE Test: 1.2857935247348335\n",
      "Degree: 9.0  Lambda: 0.01  RMSE Training: 0.7913997108584169  RMSE Test: 1.3237552755798594\n",
      "Degree: 0.0  Lambda: 0.1  RMSE Training: 0.9590469774553437  RMSE Test: 0.9590555865520022\n",
      "Degree: 1.0  Lambda: 0.1  RMSE Training: 0.8974460875670992  RMSE Test: 0.8975244507661515\n",
      "Degree: 2.0  Lambda: 0.1  RMSE Training: 0.8779350036096567  RMSE Test: 0.8782579295561325\n",
      "Degree: 3.0  Lambda: 0.1  RMSE Training: 0.8597915016036485  RMSE Test: 0.8613242146983419\n",
      "Degree: 4.0  Lambda: 0.1  RMSE Training: 0.8477427572556315  RMSE Test: 0.8487924052846504\n",
      "Degree: 5.0  Lambda: 0.1  RMSE Training: 0.8386365406892482  RMSE Test: 0.8462480737073597\n",
      "Degree: 6.0  Lambda: 0.1  RMSE Training: 0.8307957087730504  RMSE Test: 0.9027729102041849\n",
      "Degree: 7.0  Lambda: 0.1  RMSE Training: 0.8265377891516295  RMSE Test: 0.9130831414767953\n",
      "Degree: 8.0  Lambda: 0.1  RMSE Training: 0.8211060391400421  RMSE Test: 1.157216656899736\n",
      "Degree: 9.0  Lambda: 0.1  RMSE Training: 0.8187886425914248  RMSE Test: 2.6929957867167778\n",
      "Degree: 0.0  Lambda: 1.0  RMSE Training: 0.9723637729616552  RMSE Test: 0.9723689124017406\n",
      "Degree: 1.0  Lambda: 1.0  RMSE Training: 0.9399120589656771  RMSE Test: 0.9399455802742558\n",
      "Degree: 2.0  Lambda: 1.0  RMSE Training: 0.931433256411552  RMSE Test: 0.9315464333175241\n",
      "Degree: 3.0  Lambda: 1.0  RMSE Training: 0.924444240763268  RMSE Test: 0.9246036863921461\n",
      "Degree: 4.0  Lambda: 1.0  RMSE Training: 0.917686780113592  RMSE Test: 0.9210252268068124\n",
      "Degree: 5.0  Lambda: 1.0  RMSE Training: 0.9067890448326636  RMSE Test: 0.9215455134230881\n",
      "Degree: 6.0  Lambda: 1.0  RMSE Training: 0.8981124329463384  RMSE Test: 0.9066694625937959\n",
      "Degree: 7.0  Lambda: 1.0  RMSE Training: 0.891239445119521  RMSE Test: 1.0424371934292906\n",
      "Degree: 8.0  Lambda: 1.0  RMSE Training: 0.8844426969544411  RMSE Test: 1.5799881842707493\n",
      "Degree: 9.0  Lambda: 1.0  RMSE Training: 0.8771646698863883  RMSE Test: 1.4507730981608158\n",
      "\n",
      "\n",
      "\n",
      "*******JET 1 *************\n",
      "Lowest_error: 0.770414083947405  Best degree: 6.0  Best lambda: 1e-06\n"
     ]
    }
   ],
   "source": [
    "#For jet_1 => find the best hyperparameters and find the weight that corresponds to those hyperparameters\n",
    "\n",
    "[lowest_error_1,best_degree_1,best_lambda_1,rmse_tr,rmse_te] = cross_validation_ridge(5,jet_1,label_1)\n",
    "print(\"\\n\\n\")\n",
    "print(\"*******JET 1 *************\")\n",
    "print(\"Lowest_error:\",lowest_error_1,\" Best degree:\",best_degree_1,\" Best lambda:\",best_lambda_1)\n",
    "\n",
    "jet_1_extended = poly_expansion(jet_1,11)\n",
    "w_jet_1,_ = ridge(label_1,jet_1_extended,1e-7)\n",
    "#Lowest_error: 0.7620244652945832  Best degree: 7.0  Best lambda: 1e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 0.0  Lambda: 1e-15  RMSE Training: 0.9944740367271745  RMSE Test: 0.9945287227102101\n",
      "Degree: 1.0  Lambda: 1e-15  RMSE Training: 0.7858374295134061  RMSE Test: 0.7872392828855223\n",
      "Degree: 2.0  Lambda: 1e-15  RMSE Training: 0.7452029482746937  RMSE Test: 0.7457805724292732\n",
      "Degree: 3.0  Lambda: 1e-15  RMSE Training: 0.7321085077343766  RMSE Test: 0.7346318593190776\n",
      "Degree: 4.0  Lambda: 1e-15  RMSE Training: 0.7097411996966415  RMSE Test: 0.7489858375462222\n",
      "Degree: 5.0  Lambda: 1e-15  RMSE Training: 0.7081972950282911  RMSE Test: 0.7494266132410352\n",
      "Degree: 6.0  Lambda: 1e-15  RMSE Training: 0.707274534060894  RMSE Test: 1.4782147738689972\n",
      "Degree: 7.0  Lambda: 1e-15  RMSE Training: 0.7063924654202262  RMSE Test: 9.293650714408937\n",
      "Degree: 8.0  Lambda: 1e-15  RMSE Training: 0.7057996841223004  RMSE Test: 3.2109852817734277\n",
      "Degree: 9.0  Lambda: 1e-15  RMSE Training: 0.7062151156115656  RMSE Test: 2.5239920346670024\n",
      "Degree: 0.0  Lambda: 1e-14  RMSE Training: 0.9944740367271745  RMSE Test: 0.9945287227102101\n",
      "Degree: 1.0  Lambda: 1e-14  RMSE Training: 0.7858619411570369  RMSE Test: 0.7872948463580248\n",
      "Degree: 2.0  Lambda: 1e-14  RMSE Training: 0.746881978606557  RMSE Test: 0.7471963106039843\n",
      "Degree: 3.0  Lambda: 1e-14  RMSE Training: 0.7323369283512428  RMSE Test: 0.734832972565731\n",
      "Degree: 4.0  Lambda: 1e-14  RMSE Training: 0.7098560991205017  RMSE Test: 0.7492321552585464\n",
      "Degree: 5.0  Lambda: 1e-14  RMSE Training: 0.7083490948462972  RMSE Test: 0.751544655951877\n",
      "Degree: 6.0  Lambda: 1e-14  RMSE Training: 0.7074557986033442  RMSE Test: 1.4723269774165133\n",
      "Degree: 7.0  Lambda: 1e-14  RMSE Training: 0.706587453696005  RMSE Test: 9.235876070090207\n",
      "Degree: 8.0  Lambda: 1e-14  RMSE Training: 0.706005892492859  RMSE Test: 3.3409589845993786\n",
      "Degree: 9.0  Lambda: 1e-14  RMSE Training: 0.7063824811716823  RMSE Test: 2.2749314166830605\n",
      "Degree: 0.0  Lambda: 1e-13  RMSE Training: 0.9944740367271745  RMSE Test: 0.9945287227102101\n",
      "Degree: 1.0  Lambda: 1e-13  RMSE Training: 0.7861808041687698  RMSE Test: 0.7876986024627105\n",
      "Degree: 2.0  Lambda: 1e-13  RMSE Training: 0.7503196546152574  RMSE Test: 0.7504225233002378\n",
      "Degree: 3.0  Lambda: 1e-13  RMSE Training: 0.7340575043205699  RMSE Test: 0.7364767936938295\n",
      "Degree: 4.0  Lambda: 1e-13  RMSE Training: 0.7106159535540778  RMSE Test: 0.7509958835772906\n",
      "Degree: 5.0  Lambda: 1e-13  RMSE Training: 0.7087324949123133  RMSE Test: 0.7608338301265839\n",
      "Degree: 6.0  Lambda: 1e-13  RMSE Training: 0.7077192155214541  RMSE Test: 1.4059790149544131\n",
      "Degree: 7.0  Lambda: 1e-13  RMSE Training: 0.7068206799909771  RMSE Test: 9.490495170430606\n",
      "Degree: 8.0  Lambda: 1e-13  RMSE Training: 0.7062392380003572  RMSE Test: 2.903608207067232\n",
      "Degree: 9.0  Lambda: 1e-13  RMSE Training: 0.7060831129527545  RMSE Test: 4.476630868650237\n",
      "Degree: 0.0  Lambda: 1e-12  RMSE Training: 0.9944740367271745  RMSE Test: 0.9945287227102103\n",
      "Degree: 1.0  Lambda: 1e-12  RMSE Training: 0.7867173401217432  RMSE Test: 0.7882404291804469\n",
      "Degree: 2.0  Lambda: 1e-12  RMSE Training: 0.7517795114996291  RMSE Test: 0.7518284397829496\n",
      "Degree: 3.0  Lambda: 1e-12  RMSE Training: 0.7358598348283523  RMSE Test: 0.7382399222294681\n",
      "Degree: 4.0  Lambda: 1e-12  RMSE Training: 0.7126619396642268  RMSE Test: 0.753499217848637\n",
      "Degree: 5.0  Lambda: 1e-12  RMSE Training: 0.7106804824210036  RMSE Test: 0.7727613893776625\n",
      "Degree: 6.0  Lambda: 1e-12  RMSE Training: 0.7093963593666601  RMSE Test: 1.3158635801855674\n",
      "Degree: 7.0  Lambda: 1e-12  RMSE Training: 0.7083811147180817  RMSE Test: 9.95128571958592\n",
      "Degree: 8.0  Lambda: 1e-12  RMSE Training: 0.7077603429765272  RMSE Test: 2.927115392834006\n",
      "Degree: 9.0  Lambda: 1e-12  RMSE Training: 0.7075839681013538  RMSE Test: 8.290793955265606\n",
      "Degree: 0.0  Lambda: 1e-11  RMSE Training: 0.9944740367271743  RMSE Test: 0.9945287227102094\n",
      "Degree: 1.0  Lambda: 1e-11  RMSE Training: 0.7874316351106275  RMSE Test: 0.7888102739252502\n",
      "Degree: 2.0  Lambda: 1e-11  RMSE Training: 0.7522508759612165  RMSE Test: 0.7523082818499899\n",
      "Degree: 3.0  Lambda: 1e-11  RMSE Training: 0.7366659809620492  RMSE Test: 0.7389988822510082\n",
      "Degree: 4.0  Lambda: 1e-11  RMSE Training: 0.7137902902186527  RMSE Test: 0.7536747756605765\n",
      "Degree: 5.0  Lambda: 1e-11  RMSE Training: 0.7120425349802844  RMSE Test: 0.7730149492405669\n",
      "Degree: 6.0  Lambda: 1e-11  RMSE Training: 0.7108297907786718  RMSE Test: 1.3090184003027652\n",
      "Degree: 7.0  Lambda: 1e-11  RMSE Training: 0.7098740015546657  RMSE Test: 10.121289813249394\n",
      "Degree: 8.0  Lambda: 1e-11  RMSE Training: 0.709500729796709  RMSE Test: 2.8787765186313963\n",
      "Degree: 9.0  Lambda: 1e-11  RMSE Training: 0.7092290580665181  RMSE Test: 14.637155940181561\n",
      "Degree: 0.0  Lambda: 1e-10  RMSE Training: 0.9944740367271745  RMSE Test: 0.9945287227102029\n",
      "Degree: 1.0  Lambda: 1e-10  RMSE Training: 0.7908045596688521  RMSE Test: 0.7919505727579621\n",
      "Degree: 2.0  Lambda: 1e-10  RMSE Training: 0.7526426188535915  RMSE Test: 0.7526273101964965\n",
      "Degree: 3.0  Lambda: 1e-10  RMSE Training: 0.7370927560321583  RMSE Test: 0.7394281648894931\n",
      "Degree: 4.0  Lambda: 1e-10  RMSE Training: 0.7143304470496259  RMSE Test: 0.7529830946243774\n",
      "Degree: 5.0  Lambda: 1e-10  RMSE Training: 0.7127236609867413  RMSE Test: 0.7679559281763272\n",
      "Degree: 6.0  Lambda: 1e-10  RMSE Training: 0.7116020512244218  RMSE Test: 1.3745962799220348\n",
      "Degree: 7.0  Lambda: 1e-10  RMSE Training: 0.7107660828307995  RMSE Test: 9.859697253340874\n",
      "Degree: 8.0  Lambda: 1e-10  RMSE Training: 0.7104851984188667  RMSE Test: 2.3767398725351763\n",
      "Degree: 9.0  Lambda: 1e-10  RMSE Training: 0.7103453643225783  RMSE Test: 23.954631314342738\n",
      "Degree: 0.0  Lambda: 1e-09  RMSE Training: 0.9944740367271743  RMSE Test: 0.9945287227101369\n",
      "Degree: 1.0  Lambda: 1e-09  RMSE Training: 0.7960756664151126  RMSE Test: 0.7972036796433736\n",
      "Degree: 2.0  Lambda: 1e-09  RMSE Training: 0.7540444868964062  RMSE Test: 0.7538444257974929\n",
      "Degree: 3.0  Lambda: 1e-09  RMSE Training: 0.7377606433421379  RMSE Test: 0.7401602249155821\n",
      "Degree: 4.0  Lambda: 1e-09  RMSE Training: 0.7148137136505428  RMSE Test: 0.7529234042070949\n",
      "Degree: 5.0  Lambda: 1e-09  RMSE Training: 0.7132095328120455  RMSE Test: 0.76686248529845\n",
      "Degree: 6.0  Lambda: 1e-09  RMSE Training: 0.7121590552572457  RMSE Test: 1.3370144508038517\n",
      "Degree: 7.0  Lambda: 1e-09  RMSE Training: 0.7114560395341096  RMSE Test: 8.586536353676971\n",
      "Degree: 8.0  Lambda: 1e-09  RMSE Training: 0.711163241248313  RMSE Test: 2.3343799680783572\n",
      "Degree: 9.0  Lambda: 1e-09  RMSE Training: 0.7110528501801324  RMSE Test: 44.50654124829117\n",
      "Degree: 0.0  Lambda: 1e-08  RMSE Training: 0.9944740367271745  RMSE Test: 0.9945287227094786\n",
      "Degree: 1.0  Lambda: 1e-08  RMSE Training: 0.7981421691763939  RMSE Test: 0.7991881249603843\n",
      "Degree: 2.0  Lambda: 1e-08  RMSE Training: 0.7572264642061859  RMSE Test: 0.7569082501639918\n",
      "Degree: 3.0  Lambda: 1e-08  RMSE Training: 0.7401916231611991  RMSE Test: 0.7426956227256906\n",
      "Degree: 4.0  Lambda: 1e-08  RMSE Training: 0.7165860338171167  RMSE Test: 0.7532835952509045\n",
      "Degree: 5.0  Lambda: 1e-08  RMSE Training: 0.7147499524643638  RMSE Test: 0.7538785314140555\n",
      "Degree: 6.0  Lambda: 1e-08  RMSE Training: 0.7138692612663309  RMSE Test: 1.127551478887028\n",
      "Degree: 7.0  Lambda: 1e-08  RMSE Training: 0.7129629021042989  RMSE Test: 3.9937562058306937\n",
      "Degree: 8.0  Lambda: 1e-08  RMSE Training: 0.7126373648845065  RMSE Test: 8.707093158413274\n",
      "Degree: 9.0  Lambda: 1e-08  RMSE Training: 0.7124877110223069  RMSE Test: 62.311056582187824\n",
      "Degree: 0.0  Lambda: 1e-07  RMSE Training: 0.9944740367271745  RMSE Test: 0.9945287227028953\n",
      "Degree: 1.0  Lambda: 1e-07  RMSE Training: 0.7993811818901945  RMSE Test: 0.8002733496961388\n",
      "Degree: 2.0  Lambda: 1e-07  RMSE Training: 0.7592124230768876  RMSE Test: 0.7588199730252829\n",
      "Degree: 3.0  Lambda: 1e-07  RMSE Training: 0.7431377385698793  RMSE Test: 0.7456215063934365\n",
      "Degree: 4.0  Lambda: 1e-07  RMSE Training: 0.719585970056932  RMSE Test: 0.7536785357737648\n",
      "Degree: 5.0  Lambda: 1e-07  RMSE Training: 0.7179891136656892  RMSE Test: 0.7222858048564799\n",
      "Degree: 6.0  Lambda: 1e-07  RMSE Training: 0.7172362871986941  RMSE Test: 0.78124160665758\n",
      "Degree: 7.0  Lambda: 1e-07  RMSE Training: 0.7165519651417256  RMSE Test: 1.0454077831896977\n",
      "Degree: 8.0  Lambda: 1e-07  RMSE Training: 0.7161455263641804  RMSE Test: 13.000386871728107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 9.0  Lambda: 1e-07  RMSE Training: 0.7158041489154601  RMSE Test: 57.49472777965783\n",
      "Degree: 0.0  Lambda: 1e-06  RMSE Training: 0.9944740367271846  RMSE Test: 0.9945287226370698\n",
      "Degree: 1.0  Lambda: 1e-06  RMSE Training: 0.8001385143121148  RMSE Test: 0.801062158544801\n",
      "Degree: 2.0  Lambda: 1e-06  RMSE Training: 0.760229488875583  RMSE Test: 0.7597565724672231\n",
      "Degree: 3.0  Lambda: 1e-06  RMSE Training: 0.7442231385840425  RMSE Test: 0.7464459017175954\n",
      "Degree: 4.0  Lambda: 1e-06  RMSE Training: 0.7225792337053377  RMSE Test: 0.7489974180442983\n",
      "Degree: 5.0  Lambda: 1e-06  RMSE Training: 0.7200091334591534  RMSE Test: 0.7251690888375736\n",
      "Degree: 6.0  Lambda: 1e-06  RMSE Training: 0.719736889190899  RMSE Test: 1.361668152974929\n",
      "Degree: 7.0  Lambda: 1e-06  RMSE Training: 0.7193507884321407  RMSE Test: 1.4054114112174723\n",
      "Degree: 8.0  Lambda: 1e-06  RMSE Training: 0.7187609375102827  RMSE Test: 8.414272418925338\n",
      "Degree: 9.0  Lambda: 1e-06  RMSE Training: 0.7182946802410072  RMSE Test: 32.27131370370178\n",
      "Degree: 0.0  Lambda: 1e-05  RMSE Training: 0.9944740367281856  RMSE Test: 0.9945287219797254\n",
      "Degree: 1.0  Lambda: 1e-05  RMSE Training: 0.8040958372953992  RMSE Test: 0.8052684127584087\n",
      "Degree: 2.0  Lambda: 1e-05  RMSE Training: 0.7630057992688045  RMSE Test: 0.7627127969287824\n",
      "Degree: 3.0  Lambda: 1e-05  RMSE Training: 0.7469254837674992  RMSE Test: 0.7481301807984024\n",
      "Degree: 4.0  Lambda: 1e-05  RMSE Training: 0.7365390399439435  RMSE Test: 0.7467066324667854\n",
      "Degree: 5.0  Lambda: 1e-05  RMSE Training: 0.7269735155861824  RMSE Test: 0.7476432873138039\n",
      "Degree: 6.0  Lambda: 1e-05  RMSE Training: 0.7241300369711811  RMSE Test: 1.3299844899152986\n",
      "Degree: 7.0  Lambda: 1e-05  RMSE Training: 0.7237584856331022  RMSE Test: 1.3198799208257481\n",
      "Degree: 8.0  Lambda: 1e-05  RMSE Training: 0.7238165503515945  RMSE Test: 5.553234897159371\n",
      "Degree: 9.0  Lambda: 1e-05  RMSE Training: 0.7237770088629536  RMSE Test: 2.476473766100564\n",
      "Degree: 0.0  Lambda: 0.0001  RMSE Training: 0.994474036828278  RMSE Test: 0.9945287154972269\n",
      "Degree: 1.0  Lambda: 0.0001  RMSE Training: 0.8091451840922173  RMSE Test: 0.810382547107905\n",
      "Degree: 2.0  Lambda: 0.0001  RMSE Training: 0.7689633612636925  RMSE Test: 0.7689278495112235\n",
      "Degree: 3.0  Lambda: 0.0001  RMSE Training: 0.7555957893372407  RMSE Test: 0.7559842712875612\n",
      "Degree: 4.0  Lambda: 0.0001  RMSE Training: 0.7504444045228915  RMSE Test: 0.754129127557197\n",
      "Degree: 5.0  Lambda: 0.0001  RMSE Training: 0.745929791676873  RMSE Test: 0.7636123802106937\n",
      "Degree: 6.0  Lambda: 0.0001  RMSE Training: 0.7407096006558301  RMSE Test: 1.0040897258016312\n",
      "Degree: 7.0  Lambda: 0.0001  RMSE Training: 0.7368587499433469  RMSE Test: 2.2188325640669104\n",
      "Degree: 8.0  Lambda: 0.0001  RMSE Training: 0.7348149142859756  RMSE Test: 0.760323552731976\n",
      "Degree: 9.0  Lambda: 0.0001  RMSE Training: 0.7339967840855052  RMSE Test: 11.25343723075937\n",
      "Degree: 0.0  Lambda: 0.001  RMSE Training: 0.9944740468130006  RMSE Test: 0.994528659742425\n",
      "Degree: 1.0  Lambda: 0.001  RMSE Training: 0.8186860310500045  RMSE Test: 0.819346537278604\n",
      "Degree: 2.0  Lambda: 0.001  RMSE Training: 0.7852073306996663  RMSE Test: 0.785422422714993\n",
      "Degree: 3.0  Lambda: 0.001  RMSE Training: 0.769573063976187  RMSE Test: 0.7699308748712141\n",
      "Degree: 4.0  Lambda: 0.001  RMSE Training: 0.7653006025574676  RMSE Test: 0.7673766317704831\n",
      "Degree: 5.0  Lambda: 0.001  RMSE Training: 0.7634304080804358  RMSE Test: 0.7636767039883187\n",
      "Degree: 6.0  Lambda: 0.001  RMSE Training: 0.7615723088938049  RMSE Test: 0.8153892121954364\n",
      "Degree: 7.0  Lambda: 0.001  RMSE Training: 0.7587254503566774  RMSE Test: 1.6099467209508973\n",
      "Degree: 8.0  Lambda: 0.001  RMSE Training: 0.7557755292696042  RMSE Test: 2.598609348341635\n",
      "Degree: 9.0  Lambda: 0.001  RMSE Training: 0.7531243252031062  RMSE Test: 3.658648705611202\n",
      "Degree: 0.0  Lambda: 0.01  RMSE Training: 0.9944750212557851  RMSE Test: 0.9945289853163001\n",
      "Degree: 1.0  Lambda: 0.01  RMSE Training: 0.8557171964418704  RMSE Test: 0.8563707018456462\n",
      "Degree: 2.0  Lambda: 0.01  RMSE Training: 0.8276774871011219  RMSE Test: 0.8290585025665127\n",
      "Degree: 3.0  Lambda: 0.01  RMSE Training: 0.8090593934027446  RMSE Test: 0.8097444067296424\n",
      "Degree: 4.0  Lambda: 0.01  RMSE Training: 0.7979137996087163  RMSE Test: 0.7986479982759817\n",
      "Degree: 5.0  Lambda: 0.01  RMSE Training: 0.7929810472242047  RMSE Test: 0.7937472903343061\n",
      "Degree: 6.0  Lambda: 0.01  RMSE Training: 0.791088769325279  RMSE Test: 0.8219247703797145\n",
      "Degree: 7.0  Lambda: 0.01  RMSE Training: 0.7900229542059698  RMSE Test: 1.1852166781804265\n",
      "Degree: 8.0  Lambda: 0.01  RMSE Training: 0.790000691921229  RMSE Test: 2.2173970901413655\n",
      "Degree: 9.0  Lambda: 0.01  RMSE Training: 0.7891597982242484  RMSE Test: 1.657715638472591\n",
      "Degree: 0.0  Lambda: 0.1  RMSE Training: 0.9945525247637386  RMSE Test: 0.9946007535650428\n",
      "Degree: 1.0  Lambda: 0.1  RMSE Training: 0.8986548041113803  RMSE Test: 0.8991782395767391\n",
      "Degree: 2.0  Lambda: 0.1  RMSE Training: 0.8822027121712385  RMSE Test: 0.8834238392160995\n",
      "Degree: 3.0  Lambda: 0.1  RMSE Training: 0.8742962862656158  RMSE Test: 0.8753714745287325\n",
      "Degree: 4.0  Lambda: 0.1  RMSE Training: 0.8670474113829773  RMSE Test: 0.8679659686209114\n",
      "Degree: 5.0  Lambda: 0.1  RMSE Training: 0.8617800309995735  RMSE Test: 0.8684587874290403\n",
      "Degree: 6.0  Lambda: 0.1  RMSE Training: 0.858143386611018  RMSE Test: 0.8691824257233488\n",
      "Degree: 7.0  Lambda: 0.1  RMSE Training: 0.8554290780776459  RMSE Test: 1.1679516715578924\n",
      "Degree: 8.0  Lambda: 0.1  RMSE Training: 0.8535114951215353  RMSE Test: 2.9855376112282874\n",
      "Degree: 9.0  Lambda: 0.1  RMSE Training: 0.8524438475968644  RMSE Test: 0.8852827356924269\n",
      "Degree: 0.0  Lambda: 1.0  RMSE Training: 0.9963021481905863  RMSE Test: 0.9963254831619791\n",
      "Degree: 1.0  Lambda: 1.0  RMSE Training: 0.9346644774877653  RMSE Test: 0.9353068678473917\n",
      "Degree: 2.0  Lambda: 1.0  RMSE Training: 0.9242172066744633  RMSE Test: 0.9249851347675913\n",
      "Degree: 3.0  Lambda: 1.0  RMSE Training: 0.917156203560293  RMSE Test: 0.9183598277608797\n",
      "Degree: 4.0  Lambda: 1.0  RMSE Training: 0.9098232834470933  RMSE Test: 0.9111508936061714\n",
      "Degree: 5.0  Lambda: 1.0  RMSE Training: 0.9059514316800593  RMSE Test: 0.9109713008060961\n",
      "Degree: 6.0  Lambda: 1.0  RMSE Training: 0.9033221269068019  RMSE Test: 0.9078819142265526\n",
      "Degree: 7.0  Lambda: 1.0  RMSE Training: 0.900944069562794  RMSE Test: 1.1177727156366375\n",
      "Degree: 8.0  Lambda: 1.0  RMSE Training: 0.898859005417366  RMSE Test: 1.2946391785106892\n",
      "Degree: 9.0  Lambda: 1.0  RMSE Training: 0.8973261413113371  RMSE Test: 7.1766259709242535\n",
      "\n",
      "\n",
      "\n",
      "*******JET 2_3 *************\n",
      "Lowest_error: 0.7222858048564799  Best degree: 5.0  Best lambda: 1e-07\n"
     ]
    }
   ],
   "source": [
    "#For jet_2_3 => find the best hyperparameters and find the weight that corresponds to those hyperparameters\n",
    "\n",
    "[lowest_error_2_3,best_degree_2_3,best_lambda_2_3,rmse_tr,rmse_te] = cross_validation_ridge(5,jet_2_3,label_2_3)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"*******JET 2_3 *************\")\n",
    "print(\"Lowest_error:\",lowest_error_2_3,\" Best degree:\",best_degree_2_3,\" Best lambda:\",best_lambda_2_3)\n",
    "\n",
    "jet_2_3_extended = poly_expansion(jet_2_3,best_degree_2_3)\n",
    "w_jet_2_3,_ = ridge(label_2_3,jet_2_3_extended,best_lambda_2_3)\n",
    "\n",
    "#Lowest_error: 0.7222858048564799  Best degree: 5.0  Best lambda: 1e-07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '/home/adeye/Documents/EPFL/MA1/ML_course/projects/ml-project-1-aaa_project1/test.csv' \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "print(tX_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because we have split our data into three subsets we get 3 different weight vectors with different dimensions. \n",
    "#We therefore have to create the same split for our test set to be able to multiply it by the weight vectors\n",
    "jet_0_test,indices_0,jet_1_test,indices_1,jet_2_3_test,indices_2_3 = split_test_set(tX_test,best_degree_0,best_degree_1,best_degree_2_3)\n",
    "\n",
    "y_pred_jet_0 = predict_labels(w_jet_0,jet_0_test).reshape((len(y_pred_jet_0),1))\n",
    "y_pred_jet_1 = predict_labels(w_jet_1,jet_1_test).reshape((len(y_pred_jet_1),1))\n",
    "y_pred_jet_2_3 = predict_labels(w_jet_2_3,jet_2_3_test).reshape((len(y_pred_jet_2_3),1))\n",
    "\n",
    "y_pred = np.zeros((tX_test.shape[0],1))\n",
    "\n",
    "indices_0 = indices_0.reshape(-1,)\n",
    "indices_1 = indices_1.reshape(-1,)\n",
    "indices_2_3 = indices_2_3.reshape(-1,)\n",
    "\n",
    "y_pred[indices_0] = y_pred_jet_0\n",
    "y_pred[indices_1] = y_pred_jet_1\n",
    "y_pred[indices_2_3] = y_pred_jet_2_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '/home/adeye/Documents/EPFL/MA1/ML_course/projects/ml-project-1-aaa_project1/output.csv' \n",
    "#y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
