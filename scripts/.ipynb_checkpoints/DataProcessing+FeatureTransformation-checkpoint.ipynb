{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87eae00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers.least_squares import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "773da957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.proj1_helpers import *\n",
    "# Aya : '/Users/mac/Documents/GitHub/ml-project-1-aaa_project1/data/train.csv' \n",
    "DATA_TRAIN_PATH = '/home/adeye/Documents/EPFL/MA1/ML_course/projects/ml-project-1-aaa_project1/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea1c027",
   "metadata": {},
   "source": [
    "DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "affbd5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group the data into three sets, depending on whether their PRI_jet_num is {0,1,(2|3)} and return the created sets => also return the corresponding y's\n",
    "def groupy_by_jet_num(x,y):\n",
    "    #create masks to extract each one of the subsets\n",
    "    mask0 = x[:,22] == 0\n",
    "    mask1 = x[:,22] == 1\n",
    "    mask2 = x[:,22] == 2\n",
    "    mask3 = x[:,22] == 3\n",
    "    mask2_3 = np.logical_or(mask2,mask3)\n",
    "    \n",
    "    #extract the elements from each subset and return the subsets\n",
    "    jet_0 = x[mask0,:]\n",
    "    jet_1 = x[mask1,:]\n",
    "    jet_2_3 = x[mask2_3,:]\n",
    "    \n",
    "    #extract the corresponding labels\n",
    "    label_0 = y[mask0,:]\n",
    "    label_1 = y[mask1,:]\n",
    "    label_2_3 =  y[mask2_3,:]\n",
    "    return jet_0, label_0, jet_1, label_1, jet_2_3, label_2_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3bc4813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each one of the three sets, filter out the columns (features) that have only invalid (-999) values\n",
    "def remove_invalid_features(jet_0,jet_1,jet_2_3):\n",
    "    #we create a mask of the columns that are invalid for each subset\n",
    "    invalid_jet_1 = [4,5,6,12,22,23,24,25,26,27,28,29]\n",
    "    invalid_jet_2 = [4,5,6,12,22,26,27,28]\n",
    "    \n",
    "    #we remove the invalid elements from each subset\n",
    "    jet_0 = np.delete(jet_0,invalid_jet_1,axis=1)\n",
    "    jet_1 = np.delete(jet_1,invalid_jet_2,axis=1)\n",
    "\n",
    "    return jet_0,jet_1,jet_2_3\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "22c0c645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(x):\n",
    "    #go through every column and calculate it's mean\n",
    "    nbColumns = x.shape[1]\n",
    "    for i in range(nbColumns):\n",
    "        #we calculate the median of the current column after discarding the -999 values (they should not be in the median)\n",
    "        median = np.median(x[:,i][x[:,i]!= -999])\n",
    "        \n",
    "        #we find the indices of the elements with value -999 in our current column\n",
    "        indices = x[:,i] == -999\n",
    "        \n",
    "        #we replace the element at the found indices by the median of the current column\n",
    "        x[:,i][indices] = median\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5dd7d30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline for Data Processing (returns three processed datasets according to their PRI_jet_num)\n",
    "def pre_process_data_pipeline(tX,y):\n",
    "    #group by jet_num\n",
    "    jet_0, label_0, jet_1, label_1, jet_2_3, label_2_3 = groupy_by_jet_num(tX,y)\n",
    "    #remove invalid features\n",
    "    jet_0,jet_1,jet_2_3 = remove_invalid_features(jet_0,jet_1,jet_2_3)    \n",
    "    #correct reamaining invalid values\n",
    "    jet_0 = remove_outliers(jet_0)\n",
    "    jet_1 = remove_outliers(jet_1)    \n",
    "    jet_2_3 = remove_outliers(jet_2_3)\n",
    "    \n",
    "    return jet_0, label_0, jet_1, label_1, jet_2_3, label_2_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a7a8eaf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pre_process_data_pipeline() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5469/2231460245.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjet_0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjet_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjet_2_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre_process_data_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: pre_process_data_pipeline() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "jet_0,jet_1,jet_2_3 = pre_process_data_pipeline(tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1f2f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jet_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737c3a8b",
   "metadata": {},
   "source": [
    "FEATURE TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def62bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polynomial feature expansion: Takes a matrix X and returns a new matrix (1,X,X^2,...,X^n)\n",
    "def poly_expansion(x,degree):\n",
    "    poly = np.ones((len(x),1))\n",
    "    for deg in range(1,degree+1):\n",
    "        poly = np.c_[poly,np.power(x,deg)]\n",
    "    return poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9b74e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardization of the data\n",
    "def standardize(x):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0888a28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "def pca(x):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dea670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log transformation\n",
    "def log_transformation(x):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fe38f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline for Feature Transformation (returns three transformed datasets according to their PRI_jet_num)\n",
    "def feature_transformation_pipeline(tX):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
