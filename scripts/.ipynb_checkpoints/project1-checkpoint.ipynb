{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from helpers.least_squares import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from helpers.proj1_helpers import *\n",
    "# Aya : '/Users/mac/Documents/GitHub/ml-project-1-aaa_project1/data/train.csv' \n",
    "DATA_TRAIN_PATH = '/home/adeye/Documents/EPFL/MA1/ML_course/projects/ml-project-1-aaa_project1/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.gradient_descent import *\n",
    "from helpers.least_squares import *\n",
    "from helpers.stochastic_gradient_descent import *\n",
    "from helpers.ridge import *\n",
    "from helpers.processing import *\n",
    "from helpers.cross_validation import *\n",
    "from helpers.feature_transformation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing our DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jet_0,label_0,jet_1,label_1,jet_2_3, label_2_3= pre_process_data_pipeline(tX,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Algorithms After Cleaning Our DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Squares With Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jet_0,label_0,jet_1,label_1,jet_2_3, label_2_3= groupy_by_jet_num(tX,y)\n",
    "    \n",
    "remove_outliers(tX)\n",
    "init_weights = np.ones((30,))\n",
    "print(y.shape)\n",
    "print(tX.shape)\n",
    "\n",
    "weights,loss =  gradient_descent(y, tX,init_weights , 50000, .01)\n",
    "\n",
    "print(weights)\n",
    "print(\"{:e}\".format(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares with OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "weight,loss= least_squares(y,tX)\n",
    "print(compute_squared_loss(y,tX,weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares With Stochastic Gradient Descent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove_outliers(tX)\n",
    "init_weights = np.ones((30,))\n",
    "print(y.shape)\n",
    "print(tX.shape)\n",
    "\n",
    "weights,loss =  stochastic_gradient_descent(y, tX,init_weights , 500, 0.01, batch_size=1)\n",
    "\n",
    "print(weights)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares With Ridge Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weights, loss = ridge(y, tX, 0.025)\n",
    "print(\"{:e}\".format(np.sqrt(2*loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the best hyperparameters for ridge regression (degree and lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each one of our subsets we find the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 0.0  Lambda: 1e-15  RMSE Training: 0.8716352293003101  RMSE Test: 0.8739571550961067\n",
      "Degree: 1.0  Lambda: 1e-15  RMSE Training: 0.7086855263328693  RMSE Test: 0.7107033856724818\n",
      "Degree: 2.0  Lambda: 1e-15  RMSE Training: 0.6919061284061623  RMSE Test: 0.6943507155440913\n",
      "Degree: 3.0  Lambda: 1e-15  RMSE Training: 0.6844634666613373  RMSE Test: 0.6877682696069484\n",
      "Degree: 4.0  Lambda: 1e-15  RMSE Training: 0.6803593304280569  RMSE Test: 0.6839350544842328\n",
      "Degree: 5.0  Lambda: 1e-15  RMSE Training: 0.679389251616092  RMSE Test: 0.685851532246559\n",
      "Degree: 6.0  Lambda: 1e-15  RMSE Training: 4.471430442672017  RMSE Test: 3.9340782231183207\n",
      "Degree: 7.0  Lambda: 1e-15  RMSE Training: 1.5242561924239442  RMSE Test: 1.9302103982949075\n",
      "Degree: 8.0  Lambda: 1e-15  RMSE Training: 0.9903984726008506  RMSE Test: 1.036472994850342\n",
      "Degree: 9.0  Lambda: 1e-15  RMSE Training: 275684322.9719708  RMSE Test: 275147571.9826255\n",
      "Degree: 0.0  Lambda: 1e-14  RMSE Training: 0.8716352293003101  RMSE Test: 0.8739571550961067\n",
      "Degree: 1.0  Lambda: 1e-14  RMSE Training: 0.7086857595693523  RMSE Test: 0.7107006430909202\n",
      "Degree: 2.0  Lambda: 1e-14  RMSE Training: 0.6919087495954186  RMSE Test: 0.6943477566974677\n",
      "Degree: 3.0  Lambda: 1e-14  RMSE Training: 0.6845838130536162  RMSE Test: 0.6878185064413879\n",
      "Degree: 4.0  Lambda: 1e-14  RMSE Training: 0.6803994352786547  RMSE Test: 0.683953221772922\n",
      "Degree: 5.0  Lambda: 1e-14  RMSE Training: 0.6794668447582364  RMSE Test: 0.6853204606773018\n",
      "Degree: 6.0  Lambda: 1e-14  RMSE Training: 0.7321682217659327  RMSE Test: 0.7219917196260447\n",
      "Degree: 7.0  Lambda: 1e-14  RMSE Training: 0.701848437736942  RMSE Test: 0.7659892563751354\n",
      "Degree: 8.0  Lambda: 1e-14  RMSE Training: 0.7374855383573407  RMSE Test: 0.9168611346436588\n",
      "Degree: 9.0  Lambda: 1e-14  RMSE Training: 5945634.3829141725  RMSE Test: 5944183.989779579\n",
      "Degree: 0.0  Lambda: 1e-13  RMSE Training: 0.8716352293003101  RMSE Test: 0.8739571550961063\n",
      "Degree: 1.0  Lambda: 1e-13  RMSE Training: 0.708686840918159  RMSE Test: 0.710694697720796\n",
      "Degree: 2.0  Lambda: 1e-13  RMSE Training: 0.6919347161055568  RMSE Test: 0.6943516064982458\n",
      "Degree: 3.0  Lambda: 1e-13  RMSE Training: 0.684727639008728  RMSE Test: 0.6878478646741456\n",
      "Degree: 4.0  Lambda: 1e-13  RMSE Training: 0.6805301802086199  RMSE Test: 0.6840623860677012\n",
      "Degree: 5.0  Lambda: 1e-13  RMSE Training: 0.6806068795890532  RMSE Test: 0.6862334838889779\n",
      "Degree: 6.0  Lambda: 1e-13  RMSE Training: 0.6825441156186519  RMSE Test: 0.6844686575867247\n",
      "Degree: 7.0  Lambda: 1e-13  RMSE Training: 0.7022110673575035  RMSE Test: 0.979169095610002\n",
      "Degree: 8.0  Lambda: 1e-13  RMSE Training: 0.7823910517960541  RMSE Test: 0.8607218712029251\n",
      "Degree: 9.0  Lambda: 1e-13  RMSE Training: 1400750.5515916795  RMSE Test: 1411003.6035039923\n",
      "Degree: 0.0  Lambda: 1e-12  RMSE Training: 0.8716352293003101  RMSE Test: 0.8739571550961035\n",
      "Degree: 1.0  Lambda: 1e-12  RMSE Training: 0.7086875267455587  RMSE Test: 0.7106916258002716\n",
      "Degree: 2.0  Lambda: 1e-12  RMSE Training: 0.6920921864134053  RMSE Test: 0.6944374689214845\n",
      "Degree: 3.0  Lambda: 1e-12  RMSE Training: 0.6848062582196826  RMSE Test: 0.6878584448450161\n",
      "Degree: 4.0  Lambda: 1e-12  RMSE Training: 0.6806355586225065  RMSE Test: 0.6841630684934419\n",
      "Degree: 5.0  Lambda: 1e-12  RMSE Training: 0.6796636647021105  RMSE Test: 0.6850748893852211\n",
      "Degree: 6.0  Lambda: 1e-12  RMSE Training: 0.6816805655964602  RMSE Test: 0.684168242333573\n",
      "Degree: 7.0  Lambda: 1e-12  RMSE Training: 0.6945380060829776  RMSE Test: 0.835174071548791\n",
      "Degree: 8.0  Lambda: 1e-12  RMSE Training: 0.6892630925121964  RMSE Test: 0.7740451463987091\n",
      "Degree: 9.0  Lambda: 1e-12  RMSE Training: 6713617.14934901  RMSE Test: 6728430.459766845\n",
      "Degree: 0.0  Lambda: 1e-11  RMSE Training: 0.8716352293003103  RMSE Test: 0.8739571550960754\n",
      "Degree: 1.0  Lambda: 1e-11  RMSE Training: 0.7086891396563442  RMSE Test: 0.7107056866626358\n",
      "Degree: 2.0  Lambda: 1e-11  RMSE Training: 0.6923159405976778  RMSE Test: 0.6945822123326814\n",
      "Degree: 3.0  Lambda: 1e-11  RMSE Training: 0.684968460605349  RMSE Test: 0.6879151110113177\n",
      "Degree: 4.0  Lambda: 1e-11  RMSE Training: 0.6807188524060986  RMSE Test: 0.6841486423640173\n",
      "Degree: 5.0  Lambda: 1e-11  RMSE Training: 0.6801568980574194  RMSE Test: 0.685298710106332\n",
      "Degree: 6.0  Lambda: 1e-11  RMSE Training: 0.6803316449623563  RMSE Test: 0.6917214075431811\n",
      "Degree: 7.0  Lambda: 1e-11  RMSE Training: 0.7164905912702737  RMSE Test: 0.8673685217676832\n",
      "Degree: 8.0  Lambda: 1e-11  RMSE Training: 12.683293044092053  RMSE Test: 12.767656916833989\n",
      "Degree: 9.0  Lambda: 1e-11  RMSE Training: 13919090.171466608  RMSE Test: 13910935.017095586\n",
      "Degree: 0.0  Lambda: 1e-10  RMSE Training: 0.8716352293003101  RMSE Test: 0.8739571550957945\n",
      "Degree: 1.0  Lambda: 1e-10  RMSE Training: 0.7087895197699976  RMSE Test: 0.7109558452872995\n",
      "Degree: 2.0  Lambda: 1e-10  RMSE Training: 0.6923995672008324  RMSE Test: 0.6945924569947138\n",
      "Degree: 3.0  Lambda: 1e-10  RMSE Training: 0.6850715424580628  RMSE Test: 0.687986279221413\n",
      "Degree: 4.0  Lambda: 1e-10  RMSE Training: 0.6808936504931722  RMSE Test: 0.6841767141274431\n",
      "Degree: 5.0  Lambda: 1e-10  RMSE Training: 0.6798622682865311  RMSE Test: 0.6852817917623361\n",
      "Degree: 6.0  Lambda: 1e-10  RMSE Training: 0.6816041830409202  RMSE Test: 0.6861273490314865\n",
      "Degree: 7.0  Lambda: 1e-10  RMSE Training: 0.7156175340285162  RMSE Test: 1.2553421881473699\n",
      "Degree: 8.0  Lambda: 1e-10  RMSE Training: 1.8716655101869353  RMSE Test: 2.0582387708009753\n",
      "Degree: 9.0  Lambda: 1e-10  RMSE Training: 1077420.9014859074  RMSE Test: 1078146.5981584685\n",
      "Degree: 0.0  Lambda: 1e-09  RMSE Training: 0.8716352293003103  RMSE Test: 0.8739571550929854\n",
      "Degree: 1.0  Lambda: 1e-09  RMSE Training: 0.7111394676422661  RMSE Test: 0.7139585073968795\n",
      "Degree: 2.0  Lambda: 1e-09  RMSE Training: 0.6924437009182073  RMSE Test: 0.6945790022304195\n",
      "Degree: 3.0  Lambda: 1e-09  RMSE Training: 0.6851157112007209  RMSE Test: 0.6879769682941546\n",
      "Degree: 4.0  Lambda: 1e-09  RMSE Training: 0.6809643715732374  RMSE Test: 0.6841613623737282\n",
      "Degree: 5.0  Lambda: 1e-09  RMSE Training: 0.6813947596092009  RMSE Test: 0.686322549183179\n",
      "Degree: 6.0  Lambda: 1e-09  RMSE Training: 0.6919645422507967  RMSE Test: 0.71402038433872\n",
      "Degree: 7.0  Lambda: 1e-09  RMSE Training: 1.775857913611313  RMSE Test: 2.2189633470221266\n",
      "Degree: 8.0  Lambda: 1e-09  RMSE Training: 1.2458137814637624  RMSE Test: 1.9822440625246571\n",
      "Degree: 9.0  Lambda: 1e-09  RMSE Training: 394090.31430610316  RMSE Test: 394072.47894737043\n",
      "Degree: 0.0  Lambda: 1e-08  RMSE Training: 0.8716352293003103  RMSE Test: 0.873957155064895\n",
      "Degree: 1.0  Lambda: 1e-08  RMSE Training: 0.7163220836726449  RMSE Test: 0.7196342509910061\n",
      "Degree: 2.0  Lambda: 1e-08  RMSE Training: 0.6929060806441814  RMSE Test: 0.694960782350923\n",
      "Degree: 3.0  Lambda: 1e-08  RMSE Training: 0.6851833439871109  RMSE Test: 0.6879835099118917\n",
      "Degree: 4.0  Lambda: 1e-08  RMSE Training: 0.6810684538163048  RMSE Test: 0.6840257432354263\n",
      "Degree: 5.0  Lambda: 1e-08  RMSE Training: 0.6914287908093735  RMSE Test: 0.6976673105359886\n",
      "Degree: 6.0  Lambda: 1e-08  RMSE Training: 0.7802851327348949  RMSE Test: 0.7831633193516706\n",
      "Degree: 7.0  Lambda: 1e-08  RMSE Training: 1.1577547069612915  RMSE Test: 1.402448433976183\n",
      "Degree: 8.0  Lambda: 1e-08  RMSE Training: 1.7262044980879743  RMSE Test: 4.6289065043422095\n",
      "Degree: 9.0  Lambda: 1e-08  RMSE Training: 870190.7138354384  RMSE Test: 873094.4929415209\n",
      "Degree: 0.0  Lambda: 1e-07  RMSE Training: 0.8716352293003128  RMSE Test: 0.8739571547839919\n",
      "Degree: 1.0  Lambda: 1e-07  RMSE Training: 0.7185620365033232  RMSE Test: 0.7220424704063181\n",
      "Degree: 2.0  Lambda: 1e-07  RMSE Training: 0.6938768264988083  RMSE Test: 0.6960028366677288\n",
      "Degree: 3.0  Lambda: 1e-07  RMSE Training: 0.6855012711913998  RMSE Test: 0.6883171851030504\n",
      "Degree: 4.0  Lambda: 1e-07  RMSE Training: 0.6812532928562742  RMSE Test: 0.6835793750228334\n",
      "Degree: 5.0  Lambda: 1e-07  RMSE Training: 0.6805070928113405  RMSE Test: 0.6896980842108827\n",
      "Degree: 6.0  Lambda: 1e-07  RMSE Training: 0.6796963748425304  RMSE Test: 0.6875209854835567\n",
      "Degree: 7.0  Lambda: 1e-07  RMSE Training: 2.268436686859812  RMSE Test: 3.514481959574487\n",
      "Degree: 8.0  Lambda: 1e-07  RMSE Training: 4179.395111037979  RMSE Test: 3967.688670067164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 9.0  Lambda: 1e-07  RMSE Training: 3115558.2641369733  RMSE Test: 3097132.616726127\n",
      "Degree: 0.0  Lambda: 1e-06  RMSE Training: 0.8716352293005618  RMSE Test: 0.8739571519751894\n",
      "Degree: 1.0  Lambda: 1e-06  RMSE Training: 0.7189628992582472  RMSE Test: 0.7224887981787478\n",
      "Degree: 2.0  Lambda: 1e-06  RMSE Training: 0.695238276504683  RMSE Test: 0.6975853636288122\n",
      "Degree: 3.0  Lambda: 1e-06  RMSE Training: 0.6863034652271736  RMSE Test: 0.6892544599239342\n",
      "Degree: 4.0  Lambda: 1e-06  RMSE Training: 0.6824293200935875  RMSE Test: 0.6849783514984122\n",
      "Degree: 5.0  Lambda: 1e-06  RMSE Training: 0.6817114439318812  RMSE Test: 0.6893059159237941\n",
      "Degree: 6.0  Lambda: 1e-06  RMSE Training: 0.6815308777327813  RMSE Test: 0.6890642199638392\n",
      "Degree: 7.0  Lambda: 1e-06  RMSE Training: 3.4435922664728067  RMSE Test: 3.7412322581121047\n",
      "Degree: 8.0  Lambda: 1e-06  RMSE Training: 78.80885494019502  RMSE Test: 79.17844592184618\n",
      "Degree: 9.0  Lambda: 1e-06  RMSE Training: 3065101.4425722267  RMSE Test: 3097091.1979589937\n",
      "Degree: 0.0  Lambda: 1e-05  RMSE Training: 0.8716352293254616  RMSE Test: 0.8739571239098879\n",
      "Degree: 1.0  Lambda: 1e-05  RMSE Training: 0.7203547525197035  RMSE Test: 0.7239029736134098\n",
      "Degree: 2.0  Lambda: 1e-05  RMSE Training: 0.6964731635199692  RMSE Test: 0.698875068961465\n",
      "Degree: 3.0  Lambda: 1e-05  RMSE Training: 0.6881608889699039  RMSE Test: 0.6910483798928276\n",
      "Degree: 4.0  Lambda: 1e-05  RMSE Training: 0.6846930136414392  RMSE Test: 0.6877316512917462\n",
      "Degree: 5.0  Lambda: 1e-05  RMSE Training: 0.6827535477598003  RMSE Test: 0.6873033106607849\n",
      "Degree: 6.0  Lambda: 1e-05  RMSE Training: 0.683342254004323  RMSE Test: 0.7487085490274822\n",
      "Degree: 7.0  Lambda: 1e-05  RMSE Training: 1.7860579778580945  RMSE Test: 1.781015930083044\n",
      "Degree: 8.0  Lambda: 1e-05  RMSE Training: 426.9972461361419  RMSE Test: 427.97053208107366\n",
      "Degree: 9.0  Lambda: 1e-05  RMSE Training: 620865.1498002459  RMSE Test: 622351.3407784335\n",
      "Degree: 0.0  Lambda: 0.0001  RMSE Training: 0.8716352318148358  RMSE Test: 0.8739568455286811\n",
      "Degree: 1.0  Lambda: 0.0001  RMSE Training: 0.7290104088344547  RMSE Test: 0.7323546198224788\n",
      "Degree: 2.0  Lambda: 0.0001  RMSE Training: 0.7007673361066492  RMSE Test: 0.703070161023683\n",
      "Degree: 3.0  Lambda: 0.0001  RMSE Training: 0.6936890528803723  RMSE Test: 0.6963556703095033\n",
      "Degree: 4.0  Lambda: 0.0001  RMSE Training: 0.6889944719298469  RMSE Test: 0.691568369579984\n",
      "Degree: 5.0  Lambda: 0.0001  RMSE Training: 0.6887501649098169  RMSE Test: 0.6899426452313061\n",
      "Degree: 6.0  Lambda: 0.0001  RMSE Training: 0.7930696961890652  RMSE Test: 0.8177072220442921\n",
      "Degree: 7.0  Lambda: 0.0001  RMSE Training: 3.485210937842696  RMSE Test: 3.543187202999865\n",
      "Degree: 8.0  Lambda: 0.0001  RMSE Training: 134.72866718943345  RMSE Test: 135.15759749180017\n",
      "Degree: 9.0  Lambda: 0.0001  RMSE Training: 2479969.419942419  RMSE Test: 2472743.3288711184\n",
      "Degree: 0.0  Lambda: 0.001  RMSE Training: 0.8716354801425664  RMSE Test: 0.8739542882912394\n",
      "Degree: 1.0  Lambda: 0.001  RMSE Training: 0.7350526576876995  RMSE Test: 0.7384560782941918\n",
      "Degree: 2.0  Lambda: 0.001  RMSE Training: 0.7080689407871652  RMSE Test: 0.7105474355810075\n",
      "Degree: 3.0  Lambda: 0.001  RMSE Training: 0.7011501451948755  RMSE Test: 0.7036558905725705\n",
      "Degree: 4.0  Lambda: 0.001  RMSE Training: 0.696094337017671  RMSE Test: 0.6985648259548611\n",
      "Degree: 5.0  Lambda: 0.001  RMSE Training: 0.6931201122532971  RMSE Test: 0.695476258060871\n",
      "Degree: 6.0  Lambda: 0.001  RMSE Training: 21.611862687315927  RMSE Test: 21.676169153764125\n",
      "Degree: 7.0  Lambda: 0.001  RMSE Training: 19.6083948411026  RMSE Test: 19.65082100870067\n",
      "Degree: 8.0  Lambda: 0.001  RMSE Training: 47.86145765270827  RMSE Test: 47.979027918554095\n",
      "Degree: 9.0  Lambda: 0.001  RMSE Training: 4917617.520692861  RMSE Test: 4921289.609055726\n",
      "Degree: 0.0  Lambda: 0.01  RMSE Training: 0.8716597149558242  RMSE Test: 0.8739507788989643\n",
      "Degree: 1.0  Lambda: 0.01  RMSE Training: 0.7453706512193431  RMSE Test: 0.7483534518322749\n",
      "Degree: 2.0  Lambda: 0.01  RMSE Training: 0.7236014812600324  RMSE Test: 0.7261248107318051\n",
      "Degree: 3.0  Lambda: 0.01  RMSE Training: 0.7112239983328534  RMSE Test: 0.7133888387728444\n",
      "Degree: 4.0  Lambda: 0.01  RMSE Training: 0.7046524125072339  RMSE Test: 0.7074747035781019\n",
      "Degree: 5.0  Lambda: 0.01  RMSE Training: 0.7001515078470718  RMSE Test: 0.7029746062983486\n",
      "Degree: 6.0  Lambda: 0.01  RMSE Training: 3.0659524435359553  RMSE Test: 3.0626114029607443\n",
      "Degree: 7.0  Lambda: 0.01  RMSE Training: 132.32777626244584  RMSE Test: 132.80825758107642\n",
      "Degree: 8.0  Lambda: 0.01  RMSE Training: 616.8373416319885  RMSE Test: 617.5695292350797\n",
      "Degree: 9.0  Lambda: 0.01  RMSE Training: 16310753.462492157  RMSE Test: 16313761.205744023\n",
      "Degree: 0.0  Lambda: 0.1  RMSE Training: 0.8735851833072512  RMSE Test: 0.8756274193934311\n",
      "Degree: 1.0  Lambda: 0.1  RMSE Training: 0.7748816034127202  RMSE Test: 0.7774053972525445\n",
      "Degree: 2.0  Lambda: 0.1  RMSE Training: 0.7549857203510286  RMSE Test: 0.7575684523097234\n",
      "Degree: 3.0  Lambda: 0.1  RMSE Training: 0.7458877557445736  RMSE Test: 0.748481393103287\n",
      "Degree: 4.0  Lambda: 0.1  RMSE Training: 0.7399679957235301  RMSE Test: 0.7428744058204739\n",
      "Degree: 5.0  Lambda: 0.1  RMSE Training: 0.7353147974306051  RMSE Test: 0.7385590776334585\n",
      "Degree: 6.0  Lambda: 0.1  RMSE Training: 47.95947895168043  RMSE Test: 46.721709491494074\n",
      "Degree: 7.0  Lambda: 0.1  RMSE Training: 377.42024701918547  RMSE Test: 377.4359711220688\n",
      "Degree: 8.0  Lambda: 0.1  RMSE Training: 17660.091885197948  RMSE Test: 17666.556969727222\n",
      "Degree: 9.0  Lambda: 0.1  RMSE Training: 41599609.95407201  RMSE Test: 41619229.17910023\n",
      "Degree: 0.0  Lambda: 1.0  RMSE Training: 0.9160138147880945  RMSE Test: 0.9169562379337407\n",
      "Degree: 1.0  Lambda: 1.0  RMSE Training: 0.8400093568378827  RMSE Test: 0.8421091218086663\n",
      "Degree: 2.0  Lambda: 1.0  RMSE Training: 0.8308334504148736  RMSE Test: 0.8330365146573676\n",
      "Degree: 3.0  Lambda: 1.0  RMSE Training: 0.823669105524522  RMSE Test: 0.8261294599505332\n",
      "Degree: 4.0  Lambda: 1.0  RMSE Training: 0.8195785906034867  RMSE Test: 0.822066684888379\n",
      "Degree: 5.0  Lambda: 1.0  RMSE Training: 0.8127428177917624  RMSE Test: 0.8152555935020057\n",
      "Degree: 6.0  Lambda: 1.0  RMSE Training: 0.8056890480312079  RMSE Test: 0.8086253886120023\n",
      "Degree: 7.0  Lambda: 1.0  RMSE Training: 152.73277108104847  RMSE Test: 152.6703320569332\n",
      "Degree: 8.0  Lambda: 1.0  RMSE Training: 15021009.031602552  RMSE Test: 15000661.8938128\n",
      "Degree: 9.0  Lambda: 1.0  RMSE Training: 102343213.08827725  RMSE Test: 102184001.20283966\n",
      "\n",
      "\n",
      "\n",
      "*******JET 0 *************\n",
      "Lowest_error: 0.6835793750228334  Best degree: 4.0  Best lambda: 1e-07\n"
     ]
    }
   ],
   "source": [
    "#For jet_0 => find the best hyperparameters and find the weight that corresponds to those hyperparameters\n",
    "\n",
    "[lowest_error_0,best_degree_0,best_lambda_0,rmse_tr,rmse_te] = cross_validation_ridge(5,jet_0,label_0)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"*******JET 0 *************\")\n",
    "print(\"Lowest_error:\",lowest_error_0,\" Best degree:\",best_degree_0,\" Best lambda:\",best_lambda_0)\n",
    "    \n",
    "\n",
    "#X,Y = np.meshgrid(rmse_tr[:,0],rmse_tr[:,1])\n",
    "#print(X)\n",
    "#print(Y)\n",
    "\n",
    "#print(rmse_tr[:,2])\n",
    "#fig = plt.figure()\n",
    "#ax = fig.add_subplot(projection='3d')\n",
    "#ax.scatter(rmse_tr[:,0],rmse_tr[:,1],rmse_tr[:,2])\n",
    "#plt.xlim([0, 1e+08])\n",
    "\n",
    "#plt.show()\n",
    "jet_0_extended = poly_expansion(jet_0,best_degree_0)\n",
    "w_jet_0,_ = ridge(label_0,jet_0_extended,best_lambda_0)\n",
    "\n",
    "#Lowest_error: 0.6892967230876204  Best degree: 4.0  Best lambda: 1e-07\n",
    "#With interaction :  Lowest_error: 0.6664933109549022  Best degree: 7.0  Best lambda: 1e-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 0.0  Lambda: 1e-15  RMSE Training: 0.9584973728822295  RMSE Test: 0.9579899994589225\n",
      "Degree: 1.0  Lambda: 1e-15  RMSE Training: 0.8149631416765656  RMSE Test: 0.8162702046626918\n",
      "Degree: 2.0  Lambda: 1e-15  RMSE Training: 0.7879293558294564  RMSE Test: 0.7895511531071219\n",
      "Degree: 3.0  Lambda: 1e-15  RMSE Training: 0.7726699222004083  RMSE Test: 0.7753424656967318\n",
      "Degree: 4.0  Lambda: 1e-15  RMSE Training: 0.7671100580626148  RMSE Test: 0.7704316781318001\n",
      "Degree: 5.0  Lambda: 1e-15  RMSE Training: 0.7590155737086783  RMSE Test: 0.7668385629122332\n",
      "Degree: 6.0  Lambda: 1e-15  RMSE Training: 0.7676162900867368  RMSE Test: 0.8090800398563676\n",
      "Degree: 7.0  Lambda: 1e-15  RMSE Training: 0.7512704181495197  RMSE Test: 1.0338634627374654\n",
      "Degree: 8.0  Lambda: 1e-15  RMSE Training: 0.7501881890418366  RMSE Test: 3.404628836589329\n",
      "Degree: 9.0  Lambda: 1e-15  RMSE Training: 0.7519655363155178  RMSE Test: 6.778939731430185\n",
      "Degree: 0.0  Lambda: 1e-14  RMSE Training: 0.9584973728822295  RMSE Test: 0.9579899994589226\n",
      "Degree: 1.0  Lambda: 1e-14  RMSE Training: 0.814963203662501  RMSE Test: 0.8162696856139963\n",
      "Degree: 2.0  Lambda: 1e-14  RMSE Training: 0.787932512480741  RMSE Test: 0.7895555901502292\n",
      "Degree: 3.0  Lambda: 1e-14  RMSE Training: 0.7727186210083843  RMSE Test: 0.7753743273920233\n",
      "Degree: 4.0  Lambda: 1e-14  RMSE Training: 0.7671936005847156  RMSE Test: 0.7704597499088008\n",
      "Degree: 5.0  Lambda: 1e-14  RMSE Training: 0.7591577068477429  RMSE Test: 0.7667734076610486\n",
      "Degree: 6.0  Lambda: 1e-14  RMSE Training: 0.7540533634231108  RMSE Test: 0.7948158748668663\n",
      "Degree: 7.0  Lambda: 1e-14  RMSE Training: 0.7510661012234683  RMSE Test: 1.0256825326121106\n",
      "Degree: 8.0  Lambda: 1e-14  RMSE Training: 0.750301225708399  RMSE Test: 3.4776709700464954\n",
      "Degree: 9.0  Lambda: 1e-14  RMSE Training: 0.7527505131773093  RMSE Test: 8.39091138860385\n",
      "Degree: 0.0  Lambda: 1e-13  RMSE Training: 0.9584973728822295  RMSE Test: 0.9579899994589226\n",
      "Degree: 1.0  Lambda: 1e-13  RMSE Training: 0.8149658461844214  RMSE Test: 0.8162691069937648\n",
      "Degree: 2.0  Lambda: 1e-13  RMSE Training: 0.7880356134627794  RMSE Test: 0.7896913511669942\n",
      "Degree: 3.0  Lambda: 1e-13  RMSE Training: 0.7728015279725489  RMSE Test: 0.7754060981073554\n",
      "Degree: 4.0  Lambda: 1e-13  RMSE Training: 0.7672544298807147  RMSE Test: 0.7704971367544482\n",
      "Degree: 5.0  Lambda: 1e-13  RMSE Training: 0.7591894584300258  RMSE Test: 0.7668787328200966\n",
      "Degree: 6.0  Lambda: 1e-13  RMSE Training: 0.7541487687788326  RMSE Test: 0.7940957853855302\n",
      "Degree: 7.0  Lambda: 1e-13  RMSE Training: 0.7512323864939544  RMSE Test: 1.0044961371293686\n",
      "Degree: 8.0  Lambda: 1e-13  RMSE Training: 0.7506214657681963  RMSE Test: 3.5003498500915975\n",
      "Degree: 9.0  Lambda: 1e-13  RMSE Training: 0.7680115810363397  RMSE Test: 12.649086691215228\n",
      "Degree: 0.0  Lambda: 1e-12  RMSE Training: 0.9584973728822295  RMSE Test: 0.9579899994589234\n",
      "Degree: 1.0  Lambda: 1e-12  RMSE Training: 0.814979099264548  RMSE Test: 0.8162778326569644\n",
      "Degree: 2.0  Lambda: 1e-12  RMSE Training: 0.7891555549583966  RMSE Test: 0.7909097138097495\n",
      "Degree: 3.0  Lambda: 1e-12  RMSE Training: 0.7732187805350342  RMSE Test: 0.7757607808864775\n",
      "Degree: 4.0  Lambda: 1e-12  RMSE Training: 0.7673839850535908  RMSE Test: 0.7705712380890282\n",
      "Degree: 5.0  Lambda: 1e-12  RMSE Training: 0.7592474856713884  RMSE Test: 0.766796807234383\n",
      "Degree: 6.0  Lambda: 1e-12  RMSE Training: 0.7542008278989518  RMSE Test: 0.7934052558064923\n",
      "Degree: 7.0  Lambda: 1e-12  RMSE Training: 0.7514071819677607  RMSE Test: 0.985760009262971\n",
      "Degree: 8.0  Lambda: 1e-12  RMSE Training: 0.7504673833938311  RMSE Test: 3.3837073703143807\n",
      "Degree: 9.0  Lambda: 1e-12  RMSE Training: 0.7517577018382138  RMSE Test: 6.177210404067724\n",
      "Degree: 0.0  Lambda: 1e-11  RMSE Training: 0.9584973728822295  RMSE Test: 0.9579899994589294\n",
      "Degree: 1.0  Lambda: 1e-11  RMSE Training: 0.8149881532218997  RMSE Test: 0.8162828698993305\n",
      "Degree: 2.0  Lambda: 1e-11  RMSE Training: 0.7902485696217195  RMSE Test: 0.7920125923988224\n",
      "Degree: 3.0  Lambda: 1e-11  RMSE Training: 0.7749110676724208  RMSE Test: 0.777435795999448\n",
      "Degree: 4.0  Lambda: 1e-11  RMSE Training: 0.7684898778948822  RMSE Test: 0.7716446864791024\n",
      "Degree: 5.0  Lambda: 1e-11  RMSE Training: 0.7597630537987353  RMSE Test: 0.7669828106946089\n",
      "Degree: 6.0  Lambda: 1e-11  RMSE Training: 0.7544469765079365  RMSE Test: 0.7877982821047936\n",
      "Degree: 7.0  Lambda: 1e-11  RMSE Training: 0.7514341031070058  RMSE Test: 0.9434636807999339\n",
      "Degree: 8.0  Lambda: 1e-11  RMSE Training: 0.75064892401539  RMSE Test: 3.0495488139389826\n",
      "Degree: 9.0  Lambda: 1e-11  RMSE Training: 0.7501160707237263  RMSE Test: 6.263431965304398\n",
      "Degree: 0.0  Lambda: 1e-10  RMSE Training: 0.9584973728822295  RMSE Test: 0.9579899994589915\n",
      "Degree: 1.0  Lambda: 1e-10  RMSE Training: 0.8151128922109244  RMSE Test: 0.8164097468541277\n",
      "Degree: 2.0  Lambda: 1e-10  RMSE Training: 0.7904529947539503  RMSE Test: 0.7921554485285034\n",
      "Degree: 3.0  Lambda: 1e-10  RMSE Training: 0.7758755184326613  RMSE Test: 0.7783546473077815\n",
      "Degree: 4.0  Lambda: 1e-10  RMSE Training: 0.770073076325971  RMSE Test: 0.7733662827526269\n",
      "Degree: 5.0  Lambda: 1e-10  RMSE Training: 0.7614054945827837  RMSE Test: 0.7684345987646062\n",
      "Degree: 6.0  Lambda: 1e-10  RMSE Training: 0.7559150577649426  RMSE Test: 0.7783874296081882\n",
      "Degree: 7.0  Lambda: 1e-10  RMSE Training: 0.7528096710891723  RMSE Test: 0.8325558722118945\n",
      "Degree: 8.0  Lambda: 1e-10  RMSE Training: 0.7517395639573923  RMSE Test: 2.468070178641484\n",
      "Degree: 9.0  Lambda: 1e-10  RMSE Training: 0.7509142765822499  RMSE Test: 5.532700810238891\n",
      "Degree: 0.0  Lambda: 1e-09  RMSE Training: 0.9584973728822295  RMSE Test: 0.957989999459612\n",
      "Degree: 1.0  Lambda: 1e-09  RMSE Training: 0.8165653049771533  RMSE Test: 0.8180243384086087\n",
      "Degree: 2.0  Lambda: 1e-09  RMSE Training: 0.7904954313945024  RMSE Test: 0.79216550889259\n",
      "Degree: 3.0  Lambda: 1e-09  RMSE Training: 0.7760548503175093  RMSE Test: 0.7784883389032912\n",
      "Degree: 4.0  Lambda: 1e-09  RMSE Training: 0.7704833265185747  RMSE Test: 0.774053691311368\n",
      "Degree: 5.0  Lambda: 1e-09  RMSE Training: 0.7620238795690071  RMSE Test: 0.769215866496066\n",
      "Degree: 6.0  Lambda: 1e-09  RMSE Training: 0.7569178279322597  RMSE Test: 0.7783367624469953\n",
      "Degree: 7.0  Lambda: 1e-09  RMSE Training: 0.7542829806196591  RMSE Test: 0.782616941723495\n",
      "Degree: 8.0  Lambda: 1e-09  RMSE Training: 0.7534143812963129  RMSE Test: 1.8924416540137206\n",
      "Degree: 9.0  Lambda: 1e-09  RMSE Training: 0.7526028075059651  RMSE Test: 5.2270229880585575\n",
      "Degree: 0.0  Lambda: 1e-08  RMSE Training: 0.9584973728822295  RMSE Test: 0.9579899994658179\n",
      "Degree: 1.0  Lambda: 1e-08  RMSE Training: 0.8232493603943615  RMSE Test: 0.8251625212521387\n",
      "Degree: 2.0  Lambda: 1e-08  RMSE Training: 0.7908532702613947  RMSE Test: 0.7925373581742685\n",
      "Degree: 3.0  Lambda: 1e-08  RMSE Training: 0.7761721061596518  RMSE Test: 0.7786125241524333\n",
      "Degree: 4.0  Lambda: 1e-08  RMSE Training: 0.7706303134788589  RMSE Test: 0.7745348439901452\n",
      "Degree: 5.0  Lambda: 1e-08  RMSE Training: 0.762231907215166  RMSE Test: 0.7698231021878541\n",
      "Degree: 6.0  Lambda: 1e-08  RMSE Training: 0.7575705547894767  RMSE Test: 0.781286438631992\n",
      "Degree: 7.0  Lambda: 1e-08  RMSE Training: 0.7546983458574135  RMSE Test: 0.7797095936978466\n",
      "Degree: 8.0  Lambda: 1e-08  RMSE Training: 0.7539147790910954  RMSE Test: 1.37623030702329\n",
      "Degree: 9.0  Lambda: 1e-08  RMSE Training: 0.7532653250470582  RMSE Test: 4.966637056590552\n",
      "Degree: 0.0  Lambda: 1e-07  RMSE Training: 0.9584973728822301  RMSE Test: 0.9579899995278762\n",
      "Degree: 1.0  Lambda: 1e-07  RMSE Training: 0.8324127310802677  RMSE Test: 0.834518226891643\n",
      "Degree: 2.0  Lambda: 1e-07  RMSE Training: 0.793925827436236  RMSE Test: 0.7959091956251758\n",
      "Degree: 3.0  Lambda: 1e-07  RMSE Training: 0.7770660294479994  RMSE Test: 0.7796928711985284\n",
      "Degree: 4.0  Lambda: 1e-07  RMSE Training: 0.7712082264778071  RMSE Test: 0.7755872214270498\n",
      "Degree: 5.0  Lambda: 1e-07  RMSE Training: 0.7636701443344325  RMSE Test: 0.7721830061892072\n",
      "Degree: 6.0  Lambda: 1e-07  RMSE Training: 0.7583317329812008  RMSE Test: 0.7753315036961984\n",
      "Degree: 7.0  Lambda: 1e-07  RMSE Training: 0.7553431357933675  RMSE Test: 0.7695604570439892\n",
      "Degree: 8.0  Lambda: 1e-07  RMSE Training: 0.7544583417551495  RMSE Test: 1.0196822335885352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 9.0  Lambda: 1e-07  RMSE Training: 0.753770013189038  RMSE Test: 4.0871721288423535\n",
      "Degree: 0.0  Lambda: 1e-06  RMSE Training: 0.958497372882307  RMSE Test: 0.9579900001485282\n",
      "Degree: 1.0  Lambda: 1e-06  RMSE Training: 0.8346352329950519  RMSE Test: 0.8367766935325067\n",
      "Degree: 2.0  Lambda: 1e-06  RMSE Training: 0.8029530710779721  RMSE Test: 0.8052137315650814\n",
      "Degree: 3.0  Lambda: 1e-06  RMSE Training: 0.7825302421979208  RMSE Test: 0.7856195147293908\n",
      "Degree: 4.0  Lambda: 1e-06  RMSE Training: 0.7742947742671232  RMSE Test: 0.778490170123278\n",
      "Degree: 5.0  Lambda: 1e-06  RMSE Training: 0.7668406342797518  RMSE Test: 0.7756722062181541\n",
      "Degree: 6.0  Lambda: 1e-06  RMSE Training: 0.7608152825236185  RMSE Test: 0.7655684167122324\n",
      "Degree: 7.0  Lambda: 1e-06  RMSE Training: 0.7571491134559414  RMSE Test: 0.7620244652945832\n",
      "Degree: 8.0  Lambda: 1e-06  RMSE Training: 0.7559989531157487  RMSE Test: 0.8547930936893053\n",
      "Degree: 9.0  Lambda: 1e-06  RMSE Training: 0.755293306649197  RMSE Test: 2.0552911019033138\n",
      "Degree: 0.0  Lambda: 1e-05  RMSE Training: 0.9584973728899676  RMSE Test: 0.9579900063618612\n",
      "Degree: 1.0  Lambda: 1e-05  RMSE Training: 0.8354953209602787  RMSE Test: 0.8376961264085973\n",
      "Degree: 2.0  Lambda: 1e-05  RMSE Training: 0.8069241657295171  RMSE Test: 0.8092415906621861\n",
      "Degree: 3.0  Lambda: 1e-05  RMSE Training: 0.7905970913530167  RMSE Test: 0.7938308078443712\n",
      "Degree: 4.0  Lambda: 1e-05  RMSE Training: 0.7828242950401315  RMSE Test: 0.7864919554448776\n",
      "Degree: 5.0  Lambda: 1e-05  RMSE Training: 0.7745150423259494  RMSE Test: 0.7827105004184217\n",
      "Degree: 6.0  Lambda: 1e-05  RMSE Training: 0.7679138822420912  RMSE Test: 0.7722510263944264\n",
      "Degree: 7.0  Lambda: 1e-05  RMSE Training: 0.764908168219558  RMSE Test: 0.7702599815108065\n",
      "Degree: 8.0  Lambda: 1e-05  RMSE Training: 0.7631782727350732  RMSE Test: 0.7687106409478023\n",
      "Degree: 9.0  Lambda: 1e-05  RMSE Training: 0.7613621003063248  RMSE Test: 1.2742958921766605\n",
      "Degree: 0.0  Lambda: 0.0001  RMSE Training: 0.958497373655856  RMSE Test: 0.9579900691764835\n",
      "Degree: 1.0  Lambda: 0.0001  RMSE Training: 0.8386604275420705  RMSE Test: 0.8409601402922313\n",
      "Degree: 2.0  Lambda: 0.0001  RMSE Training: 0.8077981830021461  RMSE Test: 0.8102083494404573\n",
      "Degree: 3.0  Lambda: 0.0001  RMSE Training: 0.7968168253469098  RMSE Test: 0.7999443438566031\n",
      "Degree: 4.0  Lambda: 0.0001  RMSE Training: 0.7880047770637975  RMSE Test: 0.7914507115364279\n",
      "Degree: 5.0  Lambda: 0.0001  RMSE Training: 0.7806524040363865  RMSE Test: 0.7861262383588759\n",
      "Degree: 6.0  Lambda: 0.0001  RMSE Training: 0.7782251684565284  RMSE Test: 0.7820467150858067\n",
      "Degree: 7.0  Lambda: 0.0001  RMSE Training: 0.7767506808369133  RMSE Test: 0.7898519682778651\n",
      "Degree: 8.0  Lambda: 0.0001  RMSE Training: 0.7736067806468407  RMSE Test: 0.9045992071502911\n",
      "Degree: 9.0  Lambda: 0.0001  RMSE Training: 0.7714217995565392  RMSE Test: 1.0042274949491374\n",
      "Degree: 0.0  Lambda: 0.001  RMSE Training: 0.9584974500571306  RMSE Test: 0.9579907652671841\n",
      "Degree: 1.0  Lambda: 0.001  RMSE Training: 0.844378505092475  RMSE Test: 0.8466120723914878\n",
      "Degree: 2.0  Lambda: 0.001  RMSE Training: 0.8140006145061417  RMSE Test: 0.8169134712633778\n",
      "Degree: 3.0  Lambda: 0.001  RMSE Training: 0.8031581336224903  RMSE Test: 0.8061945916529094\n",
      "Degree: 4.0  Lambda: 0.001  RMSE Training: 0.7941042543871487  RMSE Test: 0.7973119163120745\n",
      "Degree: 5.0  Lambda: 0.001  RMSE Training: 0.7904675514046868  RMSE Test: 0.7938928489247914\n",
      "Degree: 6.0  Lambda: 0.001  RMSE Training: 0.7888619817835831  RMSE Test: 0.7943643428168253\n",
      "Degree: 7.0  Lambda: 0.001  RMSE Training: 0.7839524902687286  RMSE Test: 0.8001144981280449\n",
      "Degree: 8.0  Lambda: 0.001  RMSE Training: 0.7814979508571441  RMSE Test: 0.9105939899256402\n",
      "Degree: 9.0  Lambda: 0.001  RMSE Training: 0.7801955523164864  RMSE Test: 0.8149035832902424\n",
      "Degree: 0.0  Lambda: 0.01  RMSE Training: 0.9585049062898374  RMSE Test: 0.958004339577388\n",
      "Degree: 1.0  Lambda: 0.01  RMSE Training: 0.861408981662227  RMSE Test: 0.863421785540017\n",
      "Degree: 2.0  Lambda: 0.01  RMSE Training: 0.8383721247625113  RMSE Test: 0.8412637201161732\n",
      "Degree: 3.0  Lambda: 0.01  RMSE Training: 0.8178791163809741  RMSE Test: 0.8204220206887441\n",
      "Degree: 4.0  Lambda: 0.01  RMSE Training: 0.8083246915786229  RMSE Test: 0.8113066011010263\n",
      "Degree: 5.0  Lambda: 0.01  RMSE Training: 0.8047379838875732  RMSE Test: 0.808051348395027\n",
      "Degree: 6.0  Lambda: 0.01  RMSE Training: 0.798442941484545  RMSE Test: 0.8060375490616103\n",
      "Degree: 7.0  Lambda: 0.01  RMSE Training: 0.7957904992495773  RMSE Test: 0.8045491668450652\n",
      "Degree: 8.0  Lambda: 0.01  RMSE Training: 0.794508027030501  RMSE Test: 0.8082398857731532\n",
      "Degree: 9.0  Lambda: 0.01  RMSE Training: 0.791133411860808  RMSE Test: 1.0184836512604112\n",
      "Degree: 0.0  Lambda: 0.1  RMSE Training: 0.959097784682133  RMSE Test: 0.9586513893705615\n",
      "Degree: 1.0  Lambda: 0.1  RMSE Training: 0.897286801544697  RMSE Test: 0.8984690213234556\n",
      "Degree: 2.0  Lambda: 0.1  RMSE Training: 0.877809019873952  RMSE Test: 0.878709112150114\n",
      "Degree: 3.0  Lambda: 0.1  RMSE Training: 0.8597492700623146  RMSE Test: 0.8611277992985794\n",
      "Degree: 4.0  Lambda: 0.1  RMSE Training: 0.8475635636879268  RMSE Test: 0.849798319921851\n",
      "Degree: 5.0  Lambda: 0.1  RMSE Training: 0.8383633542063464  RMSE Test: 0.8421441309016385\n",
      "Degree: 6.0  Lambda: 0.1  RMSE Training: 0.8306312082218643  RMSE Test: 0.8376074749033379\n",
      "Degree: 7.0  Lambda: 0.1  RMSE Training: 0.8264037227334364  RMSE Test: 0.8447606280879876\n",
      "Degree: 8.0  Lambda: 0.1  RMSE Training: 0.8208451157724156  RMSE Test: 0.9714803259209113\n",
      "Degree: 9.0  Lambda: 0.1  RMSE Training: 0.8186579719758251  RMSE Test: 1.0493445062778926\n",
      "Degree: 0.0  Lambda: 1.0  RMSE Training: 0.97239781242772  RMSE Test: 0.972185741058875\n",
      "Degree: 1.0  Lambda: 1.0  RMSE Training: 0.9398807748650679  RMSE Test: 0.9398563508076812\n",
      "Degree: 2.0  Lambda: 1.0  RMSE Training: 0.931439397982329  RMSE Test: 0.9311583227003846\n",
      "Degree: 3.0  Lambda: 1.0  RMSE Training: 0.9244085874160192  RMSE Test: 0.9246286314417145\n",
      "Degree: 4.0  Lambda: 1.0  RMSE Training: 0.9176884797910188  RMSE Test: 0.9185280815174209\n",
      "Degree: 5.0  Lambda: 1.0  RMSE Training: 0.9068882259097585  RMSE Test: 0.9080327341196405\n",
      "Degree: 6.0  Lambda: 1.0  RMSE Training: 0.898018043214921  RMSE Test: 0.8993713878733344\n",
      "Degree: 7.0  Lambda: 1.0  RMSE Training: 0.8910959227799466  RMSE Test: 0.8956832352719799\n",
      "Degree: 8.0  Lambda: 1.0  RMSE Training: 0.8844384157173873  RMSE Test: 0.9033955849981506\n",
      "Degree: 9.0  Lambda: 1.0  RMSE Training: 0.8770267496069186  RMSE Test: 1.0982473206491814\n",
      "\n",
      "\n",
      "\n",
      "*******JET 1 *************\n",
      "Lowest_error: 0.7620244652945832  Best degree: 7.0  Best lambda: 1e-06\n"
     ]
    }
   ],
   "source": [
    "#For jet_1 => find the best hyperparameters and find the weight that corresponds to those hyperparameters\n",
    "\n",
    "[lowest_error_1,best_degree_1,best_lambda_1,rmse_tr,rmse_te] = cross_validation_ridge(5,jet_1,label_1)\n",
    "print(\"\\n\\n\")\n",
    "print(\"*******JET 1 *************\")\n",
    "print(\"Lowest_error:\",lowest_error_1,\" Best degree:\",best_degree_1,\" Best lambda:\",best_lambda_1)\n",
    "\n",
    "jet_1_extended = poly_expansion(jet_1,11)\n",
    "w_jet_1,error = ridge(label_1,jet_1_extended,1e-7)\n",
    "#Lowest_error: 0.790070090153295  Best degree: 6.0  Best lambda: 1e-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lowest_error_2_3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4815/2380800109.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#For jet_2_3 => find the best hyperparameters and find the weight that corresponds to those hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Lowest_error:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlowest_error_2_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" Best degree:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_degree_2_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" Best lambda:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_lambda_2_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlowest_error_2_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_degree_2_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_lambda_2_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrmse_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrmse_te\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation_ridge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjet_2_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_2_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lowest_error_2_3' is not defined"
     ]
    }
   ],
   "source": [
    "#For jet_2_3 => find the best hyperparameters and find the weight that corresponds to those hyperparameters\n",
    "\n",
    "[lowest_error_2_3,best_degree_2_3,best_lambda_2_3,rmse_tr,rmse_te] = cross_validation_ridge(5,jet_2_3,label_2_3)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"*******JET 2_3 *************\")\n",
    "print(\"Lowest_error:\",lowest_error_2_3,\" Best degree:\",best_degree_2_3,\" Best lambda:\",best_lambda_2_3)\n",
    "\n",
    "jet_2_3_extended = poly_expansion(jet_2_3,best_degree_2_3)\n",
    "w_jet_2_3,_ = ridge(label_2_3,jet_2_3_extended,best_lambda_2_3)\n",
    "\n",
    "#besr 0.266 => 0.729"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cross_validation_log_visualization(degrees,rmse_tr,rmse_te)\n",
    "#print(rmse_tr)\n",
    "#print(rmse_te)\n",
    "\n",
    "degree = 5\n",
    "lambda_ = 1e-07\n",
    "poly = poly_expansion(jet_0,degree)\n",
    "weight,loss = ridge(label_0, poly, lambda_)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '/home/adeye/Documents/EPFL/MA1/ML_course/projects/ml-project-1-aaa_project1/test.csv' \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "print(tX_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because we have split our data into three subsets we get 3 different weight vectors with different dimensions. \n",
    "#We therefore have to create the same split for our test set to be able to multiply it by the weight vectors\n",
    "jet_0_test,indices_0,jet_1_test,indices_1,jet_2_3_test,indices_2_3 = split_test_set(tX_test,best_degree_0,best_degree_1,best_degree_2_3)\n",
    "\n",
    "y_pred_jet_0 = predict_labels(w_jet_0,jet_0_test).reshape((len(y_pred_jet_0),1))\n",
    "y_pred_jet_1 = predict_labels(w_jet_1,jet_1_test).reshape((len(y_pred_jet_1),1))\n",
    "y_pred_jet_2_3 = predict_labels(w_jet_2_3,jet_2_3_test).reshape((len(y_pred_jet_2_3),1))\n",
    "\n",
    "y_pred = np.zeros((tX_test.shape[0],1))\n",
    "\n",
    "indices_0 = indices_0.reshape(-1,)\n",
    "indices_1 = indices_1.reshape(-1,)\n",
    "indices_2_3 = indices_2_3.reshape(-1,)\n",
    "\n",
    "y_pred[indices_0] = y_pred_jet_0\n",
    "y_pred[indices_1] = y_pred_jet_1\n",
    "y_pred[indices_2_3] = y_pred_jet_2_3\n",
    "\n",
    "print(y_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '/home/adeye/Documents/EPFL/MA1/ML_course/projects/ml-project-1-aaa_project1/output.csv' \n",
    "#y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
